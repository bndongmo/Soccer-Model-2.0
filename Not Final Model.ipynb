{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f963eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shelve\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "from skopt import Optimizer, space\n",
    "from sklearn.model_selection import KFold\n",
    "from utils import *\n",
    "from patsy import dmatrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9babee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7633\n",
      "7821\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Div</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>H_Line</th>\n",
       "      <th>A_Line</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>HXG</th>\n",
       "      <th>...</th>\n",
       "      <th>AvgC&lt;2.5</th>\n",
       "      <th>AHCh</th>\n",
       "      <th>B365CAHH</th>\n",
       "      <th>B365CAHA</th>\n",
       "      <th>PCAHH</th>\n",
       "      <th>PCAHA</th>\n",
       "      <th>MaxCAHH</th>\n",
       "      <th>MaxCAHA</th>\n",
       "      <th>AvgCAHH</th>\n",
       "      <th>AvgCAHA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SC0</td>\n",
       "      <td>08/01/20</td>\n",
       "      <td>12:30</td>\n",
       "      <td>Aberdeen</td>\n",
       "      <td>Rangers</td>\n",
       "      <td>0.724756</td>\n",
       "      <td>1.770761</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.67</td>\n",
       "      <td>...</td>\n",
       "      <td>1.78</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.83</td>\n",
       "      <td>2.02</td>\n",
       "      <td>1.90</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.94</td>\n",
       "      <td>2.12</td>\n",
       "      <td>1.85</td>\n",
       "      <td>1.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SC0</td>\n",
       "      <td>08/01/20</td>\n",
       "      <td>15:00</td>\n",
       "      <td>Dundee United</td>\n",
       "      <td>St Johnstone</td>\n",
       "      <td>1.094679</td>\n",
       "      <td>1.066453</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.49</td>\n",
       "      <td>...</td>\n",
       "      <td>1.52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.93</td>\n",
       "      <td>1.93</td>\n",
       "      <td>1.91</td>\n",
       "      <td>1.99</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.99</td>\n",
       "      <td>1.92</td>\n",
       "      <td>1.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SC0</td>\n",
       "      <td>08/01/20</td>\n",
       "      <td>15:00</td>\n",
       "      <td>Hibernian</td>\n",
       "      <td>Kilmarnock</td>\n",
       "      <td>1.511150</td>\n",
       "      <td>0.977880</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.24</td>\n",
       "      <td>...</td>\n",
       "      <td>1.76</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1.96</td>\n",
       "      <td>1.94</td>\n",
       "      <td>2.02</td>\n",
       "      <td>1.94</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SC0</td>\n",
       "      <td>08/01/20</td>\n",
       "      <td>15:00</td>\n",
       "      <td>St Mirren</td>\n",
       "      <td>Livingston</td>\n",
       "      <td>0.945194</td>\n",
       "      <td>1.182613</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>1.53</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.85</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.88</td>\n",
       "      <td>2.01</td>\n",
       "      <td>1.90</td>\n",
       "      <td>2.08</td>\n",
       "      <td>1.83</td>\n",
       "      <td>2.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SC0</td>\n",
       "      <td>08/02/20</td>\n",
       "      <td>16:30</td>\n",
       "      <td>Celtic</td>\n",
       "      <td>Hamilton</td>\n",
       "      <td>3.534317</td>\n",
       "      <td>0.420098</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3.07</td>\n",
       "      <td>...</td>\n",
       "      <td>3.79</td>\n",
       "      <td>-3.00</td>\n",
       "      <td>1.98</td>\n",
       "      <td>1.88</td>\n",
       "      <td>2.01</td>\n",
       "      <td>1.88</td>\n",
       "      <td>2.04</td>\n",
       "      <td>1.92</td>\n",
       "      <td>1.96</td>\n",
       "      <td>1.87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 109 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Div      Date   Time       HomeTeam      AwayTeam    H_Line    A_Line  \\\n",
       "0  SC0  08/01/20  12:30       Aberdeen       Rangers  0.724756  1.770761   \n",
       "1  SC0  08/01/20  15:00  Dundee United  St Johnstone  1.094679  1.066453   \n",
       "2  SC0  08/01/20  15:00      Hibernian    Kilmarnock  1.511150  0.977880   \n",
       "3  SC0  08/01/20  15:00      St Mirren    Livingston  0.945194  1.182613   \n",
       "4  SC0  08/02/20  16:30         Celtic      Hamilton  3.534317  0.420098   \n",
       "\n",
       "   FTHG  FTAG   HXG  ...  AvgC<2.5  AHCh  B365CAHH  B365CAHA PCAHH  PCAHA  \\\n",
       "0     0     1  0.67  ...      1.78  1.00      1.83      2.02  1.90   2.00   \n",
       "1     1     1  1.49  ...      1.52  0.00      1.93      1.93  1.91   1.99   \n",
       "2     2     1  1.24  ...      1.76 -0.50      1.95      1.90  1.96   1.94   \n",
       "3     1     0  0.94  ...      1.53  0.25      1.85      2.00  1.88   2.01   \n",
       "4     5     1  3.07  ...      3.79 -3.00      1.98      1.88  2.01   1.88   \n",
       "\n",
       "   MaxCAHH  MaxCAHA  AvgCAHH  AvgCAHA  \n",
       "0     1.94     2.12     1.85     1.99  \n",
       "1     2.00     1.99     1.92     1.93  \n",
       "2     2.02     1.94     1.95     1.88  \n",
       "3     1.90     2.08     1.83     2.01  \n",
       "4     2.04     1.92     1.96     1.87  \n",
       "\n",
       "[5 rows x 109 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialize dataframe, lines calculated with function to be explained later, xgs extracted from footystats sheets\n",
    "#season2021 =pd.read_csv(\"combinefd21.csv\")\n",
    "#season2022 =pd.read_csv(\"combinefd22.csv\")\n",
    "#season2023 =pd.read_csv(\"combinefd23.csv\")\n",
    "#df = pd.concat([season2021, season2022, season2023]).reset_index(drop=True)\n",
    "#print(len(season2021))\n",
    "#print(len(season2022))\n",
    "#with shelve.open('inputs') as i:\n",
    "#    hls = i['hls']\n",
    "#    als = i['als']\n",
    "#df.insert(5, 'A_Line', als)\n",
    "#df.insert(5, 'H_Line', hls)\n",
    "df = pd.read_csv('all seasons with lines.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c847be",
   "metadata": {},
   "source": [
    "Define a method to gather data from the csv and compute metrics that will be trained on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80b91a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_data(decay): # decay factor used to compute weighted averages for recency\n",
    "    # dictionaries to store stats for each team\n",
    "    goals_for = {}\n",
    "    goals_ag = {}\n",
    "    xgoals_for = {}\n",
    "    xgoals_ag = {}\n",
    "    lines_for = {}\n",
    "    lines_ag = {}\n",
    "\n",
    "    # parameter names for the metrics\n",
    "    param_names = ['goals', 'loglines']\n",
    "    param_names += ['xgoals_lines_for', 'goals_lines_for', \n",
    "                'goals_xgoals_for','wxgoals_lines_for', \n",
    "                'wgoals_lines_for', 'wgoals_xgoals_for']\n",
    "    param_names += ['xgoals_lines_ag', 'goals_lines_ag', \n",
    "                    'goals_xgoals_ag','wxgoals_lines_ag', \n",
    "                    'wgoals_lines_ag', 'wgoals_xgoals_ag']\n",
    "    # minimum sample size for teams before betting on a match\n",
    "    min_sample_size = 8\n",
    "\n",
    "    # list to store training data rows\n",
    "    training_rows = []\n",
    "\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for index, row in df.iterrows(): \n",
    "        if index == 7633 or index == 7633+7821: #new seasons\n",
    "            goals_for = {}\n",
    "            goals_ag = {}\n",
    "            xgoals_for = {}\n",
    "            xgoals_ag = {}\n",
    "            lines_for = {}\n",
    "            lines_ag = {}\n",
    "            \n",
    "        home_team = row['HomeTeam']\n",
    "        away_team = row['AwayTeam']\n",
    "        h_line = row['H_Line']\n",
    "        a_line = row['A_Line']\n",
    "        h_goals = row['FTHG']\n",
    "        a_goals = row['FTAG']\n",
    "\n",
    "        # Check if both teams have sufficient data for betting\n",
    "        if home_team in goals_for and away_team in goals_for and len(goals_for[home_team]) >= min_sample_size and len(goals_for[away_team]) >= min_sample_size and sum(goals_for[home_team])>0 and sum(goals_for[away_team])>0 and sum(goals_ag[home_team])>0 and sum(goals_ag[away_team])>0:\n",
    "\n",
    "            # Calculate various metrics for home and away teams\n",
    "            h_xgoals_vs_lines_for, h_goals_vs_lines_for, h_goals_vs_xgoals_for, h_xgoals_vs_lines_ag, h_goals_vs_lines_ag, h_goals_vs_xgoals_ag = metrics(home_team, goals_for, goals_ag, xgoals_for, xgoals_ag, lines_for, lines_ag)\n",
    "            a_xgoals_vs_lines_for, a_goals_vs_lines_for, a_goals_vs_xgoals_for, a_xgoals_vs_lines_ag, a_goals_vs_lines_ag, a_goals_vs_xgoals_ag = metrics(away_team, goals_for, goals_ag, xgoals_for, xgoals_ag, lines_for, lines_ag)\n",
    "            weighted_h_xgoals_vs_lines_for, weighted_h_goals_vs_lines_for, weighted_h_goals_vs_xgoals_for, weighted_h_xgoals_vs_lines_ag, weighted_h_goals_vs_lines_ag, weighted_h_goals_vs_xgoals_ag = metrics(home_team, goals_for, goals_ag, xgoals_for, xgoals_ag, lines_for, lines_ag, True, decay)\n",
    "            weighted_a_xgoals_vs_lines_for, weighted_a_goals_vs_lines_for, weighted_a_goals_vs_xgoals_for, weighted_a_xgoals_vs_lines_ag, weighted_a_goals_vs_lines_ag, weighted_a_goals_vs_xgoals_ag = metrics(away_team, goals_for, goals_ag, xgoals_for, xgoals_ag, lines_for, lines_ag, True, decay)\n",
    "\n",
    "            # Apply the convert_metric function to each metric for home and away teams\n",
    "            home_metrics = [h_xgoals_vs_lines_for, h_goals_vs_lines_for, h_goals_vs_xgoals_for, weighted_h_xgoals_vs_lines_for, weighted_h_goals_vs_lines_for, weighted_h_goals_vs_xgoals_for]\n",
    "            home_metrics += [a_xgoals_vs_lines_ag, a_goals_vs_lines_ag, a_goals_vs_xgoals_ag, weighted_a_xgoals_vs_lines_ag, weighted_a_goals_vs_lines_ag, weighted_a_goals_vs_xgoals_ag]\n",
    "            away_metrics = [a_xgoals_vs_lines_for, a_goals_vs_lines_for, a_goals_vs_xgoals_for, weighted_a_xgoals_vs_lines_for, weighted_a_goals_vs_lines_for, weighted_a_goals_vs_xgoals_for]\n",
    "            away_metrics += [h_xgoals_vs_lines_ag, h_goals_vs_lines_ag, h_goals_vs_xgoals_ag, weighted_h_xgoals_vs_lines_ag, weighted_h_goals_vs_lines_ag, weighted_h_goals_vs_xgoals_ag]\n",
    "\n",
    "            for i in range(12):\n",
    "                home_metrics[i] = convert_metric(h_line, home_metrics[i])\n",
    "                away_metrics[i] = convert_metric(a_line, away_metrics[i])\n",
    "\n",
    "            # Create complete metrics Series for home and away teams\n",
    "            complete_home_metrics = pd.Series([h_goals, np.log(h_line*1.024)]+home_metrics,index=param_names)\n",
    "            complete_away_metrics = pd.Series([a_goals, np.log(a_line*1.024)]+away_metrics,index=param_names)\n",
    "\n",
    "            # Append the metrics Series to the training_rows list\n",
    "            training_rows.append(complete_home_metrics)\n",
    "            training_rows.append(complete_away_metrics)\n",
    "\n",
    "        # Update the dictionaries with new data for goals, expected goals, and lines\n",
    "        h_xg = row['HXG']\n",
    "        a_xg = row['AXG']\n",
    "        if h_xg > 0 and abs(a_xg) > 0:\n",
    "            goals_for[home_team] = goals_for.setdefault(home_team, [])+[h_goals]\n",
    "            goals_for[away_team] = goals_for.setdefault(away_team, [])+[a_goals]\n",
    "            goals_ag[home_team] = goals_ag.setdefault(home_team, [])+[a_goals]\n",
    "            goals_ag[away_team] = goals_ag.setdefault(away_team, [])+[h_goals]\n",
    "            xgoals_for[home_team] = xgoals_for.setdefault(home_team, [])+[h_xg]\n",
    "            xgoals_for[away_team] = xgoals_for.setdefault(away_team, [])+[a_xg]\n",
    "            xgoals_ag[home_team] = xgoals_ag.setdefault(home_team, [])+[a_xg]\n",
    "            xgoals_ag[away_team] = xgoals_ag.setdefault(away_team, [])+[h_xg]\n",
    "            lines_for[home_team] = lines_for.setdefault(home_team, [])+[h_line]\n",
    "            lines_for[away_team] = lines_for.setdefault(away_team, [])+[a_line]\n",
    "            lines_ag[home_team] = lines_ag.setdefault(home_team, [])+[a_line]\n",
    "            lines_ag[away_team] = lines_ag.setdefault(away_team, [])+[h_line]\n",
    "    return training_rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01f81b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather the training data based on the best decay value\n",
    "training_rows = gather_data(.93)\n",
    "data = pd.concat(training_rows, axis=1).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe29283b",
   "metadata": {},
   "source": [
    "Separate the data into predictors and response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68c8017e",
   "metadata": {},
   "outputs": [],
   "source": [
    "expr = 'goals ~ loglines'\n",
    "for name in data.columns[2:]:\n",
    "    expr += ' + '+name\n",
    "    \n",
    "y, X = dmatrices(expr, data, return_type='matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa659bc2",
   "metadata": {},
   "source": [
    "Functions also defined in utils but rewritten to facilitate gradient computation, will be added to a module summarizing the key functions used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5be2b2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpmf(y, lamb, alpha):\n",
    "    ay = alpha*y\n",
    "    lay = lamb+ay\n",
    "    term = np.exp(-(lay))\n",
    "    term2 = np.power(lay, y-2)\n",
    "    fact = factorial(y)\n",
    "\n",
    "    p = lamb * term * np.power(lay, y-1) / fact\n",
    "\n",
    "    numerator = -1\n",
    "    numerator *= term2*(np.power(lamb, 2)+(alpha-1)*y*lamb-ay)*term\n",
    "    dp_dlamb = numerator / fact\n",
    "\n",
    "    numerator = -1\n",
    "    numerator *= lamb*y*term2*(ay-y+lamb+1)*term\n",
    "    dp_dalpha = numerator / fact\n",
    "\n",
    "    p = np.where(p <= 0, 1e-8, p)\n",
    "    p = np.where(p > 1, 1, p)\n",
    "    return p, dp_dlamb, dp_dalpha\n",
    "\n",
    "def objective(params, X, y, grad=False):\n",
    "    params = params.reshape(-1, 1)\n",
    "    beta1 = np.array(params[:14])\n",
    "    beta2 = np.array(params[14:])\n",
    "    lamb = np.exp(X @ beta1)\n",
    "    tan = np.tanh(X @ beta2)\n",
    "    alpha = tan*.1-.024\n",
    "\n",
    "    p, dp_dlamb, dp_dalpha = gpmf(y, lamb, alpha)\n",
    "    if grad:\n",
    "        dloss_dp = -1/p\n",
    "        dlamb_dbeta1 = lamb*X\n",
    "        dalpha_dbeta2 = (1-np.power(tan, 2)) * .1 * X\n",
    "\n",
    "        dloss_dbeta1 = dloss_dp * dp_dlamb * dlamb_dbeta1\n",
    "        dloss_dbeta2 = dloss_dp * dp_dalpha * dalpha_dbeta2\n",
    "        jac1 = np.mean(dloss_dbeta1.T, axis=1)\n",
    "        jac2 = np.mean(dloss_dbeta2.T, axis=1)\n",
    "        jac = np.hstack((jac1, jac2))\n",
    "    return -np.mean(np.log(p)), jac"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b06512",
   "metadata": {},
   "source": [
    "Start without L1/L2 regularization. Borrow from neural nets and incorporate early stopping across the scipy.minimize methods to determine optimal number of iterations. To be cleaned up for module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad7e7213",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_minimize.py:550: RuntimeWarning: Method nelder-mead does not use gradient information (jac).\n",
      "  warn('Method %s does not use gradient information (jac).' % method,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated: Cross validation showing no signs of improving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_minimize.py:550: RuntimeWarning: Method powell does not use gradient information (jac).\n",
      "  warn('Method %s does not use gradient information (jac).' % method,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated: Cross validation showing no signs of improving\n",
      "Optimization terminated: Cross validation showing no signs of improving\n",
      "Optimization terminated: Timeout\n",
      "Optimization terminated: Cross validation showing no signs of improving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bryant Ndongmo\\AppData\\Local\\Temp\\ipykernel_11724\\13555808.py:35: DeprecationWarning: 'maxiter' has been deprecated in favor of 'maxfun' and will be removed in SciPy 1.11.0.\n",
      "  result = minimize(objective, params, args=(X_train,y_train), method=method, jac=True, callback=callback, options={'maxiter': 1000})\n",
      "C:\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_minimize.py:550: RuntimeWarning: Method cobyla does not use gradient information (jac).\n",
      "  warn('Method %s does not use gradient information (jac).' % method,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated: Timeout\n",
      "Optimization terminated: Cross validation showing no signs of improving\n",
      "Optimization terminated: Cross validation showing no signs of improving\n",
      "Optimization terminated: Cross validation showing no signs of improving\n",
      "Optimization terminated: Cross validation showing no signs of improving\n",
      "Optimization terminated: Cross validation showing no signs of improving\n",
      "Optimization terminated: Cross validation showing no signs of improving\n",
      "Optimization terminated: Cross validation showing no signs of improving\n",
      "Optimization terminated: Cross validation showing no signs of improving\n",
      "Optimization terminated: Timeout\n",
      "Optimization terminated: Timeout\n",
      "Optimization terminated: Cross validation showing no signs of improving\n",
      "Optimization terminated: Cross validation showing no signs of improving\n",
      "Optimization terminated: Cross validation showing no signs of improving\n",
      "Optimization terminated: Cross validation showing no signs of improving\n",
      "Optimization terminated: Cross validation showing no signs of improving\n",
      "Optimization terminated: Cross validation showing no signs of improving\n",
      "Optimization terminated: Cross validation showing no signs of improving\n",
      "Optimization terminated: Cross validation showing no signs of improving\n",
      "Optimization terminated: Cross validation showing no signs of improving\n",
      "Optimization terminated: Cross validation showing no signs of improving\n",
      "Optimization terminated: Cross validation showing no signs of improving\n",
      "Optimization terminated: Cross validation showing no signs of improving\n",
      "Optimization terminated: Cross validation showing no signs of improving\n",
      "Optimization terminated: Cross validation showing no signs of improving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bryant Ndongmo\\AppData\\Local\\Temp\\ipykernel_11724\\13555808.py:35: DeprecationWarning: 'maxiter' has been deprecated in favor of 'maxfun' and will be removed in SciPy 1.11.0.\n",
      "  result = minimize(objective, params, args=(X_train,y_train), method=method, jac=True, callback=callback, options={'maxiter': 1000})\n",
      "C:\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_minimize.py:550: RuntimeWarning: Method cobyla does not use gradient information (jac).\n",
      "  warn('Method %s does not use gradient information (jac).' % method,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated: Timeout\n",
      "Optimization terminated: Cross validation showing no signs of improving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_minimize.py:550: RuntimeWarning: Method nelder-mead does not use gradient information (jac).\n",
      "  warn('Method %s does not use gradient information (jac).' % method,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated: Cross validation showing no signs of improving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_minimize.py:550: RuntimeWarning: Method powell does not use gradient information (jac).\n",
      "  warn('Method %s does not use gradient information (jac).' % method,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated: Timeout\n",
      "Optimization terminated: Cross validation showing no signs of improving\n",
      "Optimization terminated: Cross validation showing no signs of improving\n",
      "Optimization terminated: Cross validation showing no signs of improving\n",
      "Optimization terminated: Cross validation showing no signs of improving\n",
      "Optimization terminated: Cross validation showing no signs of improving\n",
      "Optimization terminated: Cross validation showing no signs of improving\n",
      "Optimization terminated: Cross validation showing no signs of improving\n",
      "Optimization terminated: Cross validation showing no signs of improving\n",
      "Optimization terminated: Cross validation showing no signs of improving\n",
      "Optimization terminated: Cross validation showing no signs of improving\n",
      "Optimization terminated: Cross validation showing no signs of improving\n",
      "Optimization terminated: Timeout\n",
      "Optimization terminated: Cross validation showing no signs of improving\n",
      "Optimization terminated: Cross validation showing no signs of improving\n",
      "Optimization terminated: Cross validation showing no signs of improving\n",
      "Optimization terminated: Cross validation showing no signs of improving\n",
      "Optimization terminated: Timeout\n",
      "Optimization terminated: Cross validation showing no signs of improving\n",
      "Optimization terminated: Cross validation showing no signs of improving\n",
      "Optimization terminated: Cross validation showing no signs of improving\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=10)  # Define the number of folds\n",
    "cv_losses = {}\n",
    "methods = ['nelder-mead', 'powell', 'cg', 'bfgs', 'newton-cg', 'l-bfgs-b', 'tnc', 'cobyla', 'slsqp', 'trust-constr']\n",
    "for method in methods:\n",
    "    cv_losses[method] = {}\n",
    "    for i in range(1, 1001):\n",
    "        cv_losses[method][i] = []\n",
    "for train_index, val_index in kf.split(X):\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "    score = {}\n",
    "    results = {}\n",
    "    \n",
    "    for method in methods:\n",
    "        progress = {'start_time': time.time(), 'iters':0, 'iters_since_improvement':0, 'best_cv':float('inf'), 'best_iter': None, 'best_params': None}\n",
    "        def callback(xk,state=None):\n",
    "            cv_loss = objective(xk, X_val, y_val)[0]\n",
    "            cv_losses[method][progress['iters']+1].append(cv_loss)\n",
    "            if cv_loss < progress['best_cv']:\n",
    "                progress['best_cv'] = cv_loss\n",
    "                progress['iters_since_improvement'] = 0\n",
    "                progress['best_iter'] = progress['iters'] + 1\n",
    "                progress['best_params'] = xk\n",
    "            else:\n",
    "                progress['iters_since_improvement'] += 1\n",
    "                if progress['iters'] > 100 and progress['iters_since_improvement'] > (progress['iters']+1)*.8:\n",
    "                    raise Exception(\"Cross validation showing no signs of improving\")\n",
    "            if time.time() - progress['start_time'] > 20:\n",
    "                raise Exception(\"Timeout\")\n",
    "\n",
    "            progress['iters'] += 1\n",
    "        params = np.array([0, 1]+[0]*26).T\n",
    "        try:\n",
    "            result = minimize(objective, params, args=(X_train,y_train), method=method, jac=True, callback=callback, options={'maxiter': 1000})\n",
    "        except Exception as e:\n",
    "            pass\n",
    "            # Exception handling code\n",
    "            print(\"Optimization terminated:\", str(e))\n",
    "        #print(method, progress['best_cv'])\n",
    "        score[method] = progress['best_cv']\n",
    "        results[method] = progress\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422a4b17",
   "metadata": {},
   "source": [
    "Determine the best average cv loss with method and number of iterations. Appears bfgs with 51 iterations is best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da01efff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cg 14 1.41448252076091\n",
      "cg 22 1.4144885978499997\n",
      "cg 23 1.4144814265807233\n",
      "cg 38 1.4144964544980958\n",
      "cg 53 1.4144966321584778\n",
      "cg 58 1.4144977384178583\n",
      "cg 60 1.4144893671254724\n",
      "cg 61 1.4144849000193052\n",
      "cg 62 1.4144891457371125\n",
      "cg 63 1.4144917642044572\n",
      "cg 66 1.4144949944857736\n",
      "bfgs 48 1.4144966441185165\n",
      "bfgs 49 1.4144814235686818\n",
      "bfgs 50 1.4144567918366358\n",
      "bfgs 51 1.4144311578221749\n",
      "bfgs 52 1.4144327294441514\n",
      "bfgs 53 1.4144482682950255\n",
      "bfgs 54 1.414457640644838\n",
      "bfgs 55 1.414459758004704\n",
      "bfgs 56 1.414461444814271\n",
      "bfgs 57 1.414463786056896\n",
      "bfgs 58 1.4144675250932544\n",
      "bfgs 59 1.414473941976755\n",
      "bfgs 60 1.4144855537382799\n",
      "l-bfgs-b 23 1.4144856490140374\n",
      "l-bfgs-b 24 1.4144691826015572\n",
      "l-bfgs-b 25 1.4144412900974142\n",
      "l-bfgs-b 26 1.4144523091555574\n",
      "l-bfgs-b 27 1.4144616246022852\n",
      "l-bfgs-b 28 1.414456234699404\n",
      "l-bfgs-b 29 1.4144689100542387\n",
      "l-bfgs-b 30 1.414467789090414\n",
      "l-bfgs-b 31 1.4144679442153003\n",
      "l-bfgs-b 32 1.414474103248982\n",
      "l-bfgs-b 33 1.4144810092662137\n",
      "l-bfgs-b 34 1.4144877157125508\n",
      "trust-constr 32 1.414495323949898\n",
      "trust-constr 33 1.4144914383705238\n",
      "trust-constr 35 1.4144831017087778\n",
      "trust-constr 36 1.4144931788103903\n",
      "trust-constr 37 1.414480442171206\n",
      "trust-constr 38 1.4144791753003543\n",
      "trust-constr 39 1.4144746899461516\n",
      "trust-constr 40 1.4144510050057226\n",
      "trust-constr 41 1.4144478129610714\n",
      "trust-constr 42 1.4144464342775047\n",
      "trust-constr 43 1.4144476657112608\n",
      "trust-constr 44 1.4144539192425356\n",
      "trust-constr 45 1.414447720849573\n",
      "trust-constr 46 1.414450951411058\n",
      "trust-constr 47 1.4144767368982172\n",
      "trust-constr 48 1.4144698083849814\n",
      "trust-constr 49 1.414465880723013\n",
      "trust-constr 50 1.414468974744717\n",
      "trust-constr 51 1.414459974229814\n",
      "trust-constr 52 1.4144725821203006\n",
      "trust-constr 53 1.414489221407661\n",
      "trust-constr 55 1.414496530431379\n",
      "[1.417419465394517, 1.3736383503022003, 1.412737785238612, 1.4434338027240317, 1.4199216745272034, 1.3942130324647228, 1.4470218407953221, 1.4085974355543467, 1.3913452739482084, 1.4364814317129742]\n"
     ]
    }
   ],
   "source": [
    "best_loss = np.inf\n",
    "for method in methods:\n",
    "    for i in range(1,1001):\n",
    "        l = cv_losses[method][i]\n",
    "        if len(l) == 10:\n",
    "            loss = sum(l)/10\n",
    "            if loss <= best_loss:\n",
    "                best_loss = loss\n",
    "            if loss <= 1.4145:\n",
    "                print(method, i, loss)\n",
    "\n",
    "print(cv_losses['bfgs'][51])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4a01f980",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#cg, bfgs, l-bfgs-b, trust-constr seem to be best, time to introduce L1/L2 regularization\n",
    "def objective_regularized(params, X, y, l1_wt1=0, l2_wt1=0, l1_wt2=0, l2_wt2=0):\n",
    "    params = params.reshape(-1, 1)\n",
    "    beta1 = np.array(params[:14])\n",
    "    beta2 = np.array(params[14:])\n",
    "    lamb = np.exp(X @ beta1)\n",
    "    tan = np.tanh(X @ beta2)\n",
    "    alpha = tan*.1-.024\n",
    "\n",
    "    p, dp_dlamb, dp_dalpha = gpmf(y, lamb, alpha)\n",
    "\n",
    "    dloss_dp = -1/p\n",
    "    dlamb_dbeta1 = lamb*X\n",
    "    dalpha_dbeta2 = (1-np.power(tan, 2)) * .1 * X\n",
    "\n",
    "    dloss_dbeta1 = dloss_dp * dp_dlamb * dlamb_dbeta1\n",
    "    dloss_dbeta2 = dloss_dp * dp_dalpha * dalpha_dbeta2\n",
    "    jac1 = np.mean(dloss_dbeta1.T+l1_wt1*np.sign(beta1)+l2_wt1*2*beta1, axis=1)\n",
    "    jac2 = np.mean(dloss_dbeta2.T+l1_wt2*np.sign(beta2)+l2_wt2*2*beta2, axis=1)\n",
    "    jac = np.hstack((jac1, jac2))\n",
    "    \n",
    "    adj1 = abs(beta1[1]-1)-abs(beta1[1])\n",
    "    adj2 = (beta1[1]-1)**2-beta1[1]**2\n",
    "    l1_penalty = l1_wt1*(np.linalg.norm(beta1, ord=1)+adj1)+l1_wt2*np.linalg.norm(beta2, ord=1)\n",
    "    l2_penalty = l1_wt2*(np.linalg.norm(beta1, ord=2)**2+adj2)+l2_wt2*np.linalg.norm(beta2, ord=2)**2\n",
    "    \n",
    "    return -np.mean(np.log(p)) + l1_penalty + l2_penalty, jac\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1860003",
   "metadata": {},
   "source": [
    "Function that takes in parameters to test multiple methods with given l1/l2 regularization weights and carry out early stopping to determine performance of method, iteration, penalty combo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "321c75d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = ['cg', 'bfgs', 'l-bfgs-b','trust-constr']\n",
    "def cross_validate(X, y, l1_wt_1, l2_wt_1, l1_wt_2, l2_wt_2, splits=10, methods = ['cg', 'bfgs', 'l-bfgs-b','trust-constr'], min_iter= 60, max_iter=1000, patience=.8, timeout=20, best_loss=float('inf')):\n",
    "    kf = KFold(n_splits=splits)  # Define the number of folds\n",
    "    cv_losses = {}\n",
    "    for method in methods:\n",
    "        cv_losses[method] = {}\n",
    "        for i in range(1, max_iter+1):\n",
    "            cv_losses[method][i] = []\n",
    "    for train_index, val_index in kf.split(X):\n",
    "        X_train, X_val = X[train_index], X[val_index]\n",
    "        y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "        score = {}\n",
    "        results = {}\n",
    "\n",
    "        for method in methods:\n",
    "            progress = {'start_time': time.time(), 'iters':0, 'iters_since_improvement':0, 'best_cv':float('inf'), 'best_iter': None, 'best_params': None}\n",
    "            def callback(xk,state=None):\n",
    "                cv_loss = objective(xk, X_val, y_val)[0]\n",
    "                cv_losses[method][progress['iters']+1].append(cv_loss)\n",
    "                if cv_loss < progress['best_cv']:\n",
    "                    progress['best_cv'] = cv_loss\n",
    "                    progress['iters_since_improvement'] = 0\n",
    "                    progress['best_iter'] = progress['iters'] + 1\n",
    "                    progress['best_params'] = xk\n",
    "                else:\n",
    "                    progress['iters_since_improvement'] += 1\n",
    "                    if progress['iters'] > min_iter and progress['iters_since_improvement'] > (progress['iters']+1)*patience:\n",
    "                        raise Exception(\"Cross validation showing no signs of improving\")\n",
    "                if time.time() - progress['start_time'] > timeout:\n",
    "                    raise Exception(\"Timeout\")\n",
    "\n",
    "                progress['iters'] += 1\n",
    "            params = np.array([0, 1]+[0]*26).T\n",
    "            try:\n",
    "                result = minimize(objective_regularized, params, args=(X_train,y_train,l1_wt_1, l2_wt_1, l1_wt_2, l2_wt_2), method=method, jac=True, callback=callback, options={'maxiter': 1000})\n",
    "            except Exception as e:\n",
    "                pass\n",
    "                # Exception handling code\n",
    "                #print(\"Optimization terminated:\", str(e))\n",
    "            score[method] = progress['best_cv']\n",
    "            results[method] = progress\n",
    "            #print(method, score[method])\n",
    "    for method in methods:\n",
    "        for i in range(1,max_iter+1):\n",
    "            l = cv_losses[method][i]\n",
    "            if len(l) == splits:\n",
    "                loss = sum(l)/splits\n",
    "                if loss <= best_loss:\n",
    "                    #print(method, i, loss)\n",
    "                    best_loss = loss\n",
    "                    best = (method, i)\n",
    "    return best_loss, best\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4e9946e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((4.239409459284336e-09, 4.2828433177175073e-07, 3.312701637144262e-07, 3.004915120543764e-09), ('bfgs', 51)) 1.4144314690562643\n",
      "((5.559928228152292e-05, 3.2694549621703335e-10, 1.0544385116905289e-08, 9.597776031038723e-08), ('trust-constr', 43)) 1.4144195519707425\n",
      "((5.396718822844268e-05, 5.008739999507359e-07, 1e-10, 1e-10), ('trust-constr', 46)) 1.414418936660207\n"
     ]
    }
   ],
   "source": [
    "bayes_result = {}\n",
    "def bayes_objective(x):\n",
    "    l1_wt_1, l2_wt_1, l1_wt_2, l2_wt_2 = x\n",
    "    cv = cross_validate(X, y, l1_wt_1, l2_wt_1, l1_wt_2, l2_wt_2)\n",
    "    bayes_result[tuple(x)] = cv[1]\n",
    "    return cv[0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sp = [space.Real(1e-10, .001, name='l1_wt_1', prior='log-uniform'), space.Real(1e-10, .1, name='l2_wt_1', prior='log-uniform')]\n",
    "sp += [space.Real(1e-10, .001, name='l1_wt_2', prior='log-uniform'), space.Real(1e-10, 1, name='l2_wt_2', prior='log-uniform')]\n",
    "\n",
    "# Create an instance of Optimizer for Bayesian optimization and optimize\n",
    "optimizer = Optimizer(sp, base_estimator='gp')\n",
    "\n",
    "# Set the desired timeout in seconds\n",
    "timeout_seconds = 3600 * 10 # 10 hours\n",
    "\n",
    "# Perform Bayesian optimization iterations with timeout\n",
    "start_time = time.time()\n",
    "elapsed_time = 0\n",
    "iters_since_improvement = 0\n",
    "iters = 0\n",
    "best_loss = np.inf\n",
    "best = None\n",
    "while iters < 60 or iters_since_improvement > .2 * iters:\n",
    "    optimizer.run(bayes_objective, n_iter=1)  # Run a single iteration\n",
    "    Xi = optimizer.Xi\n",
    "    yi = optimizer.yi\n",
    "    if yi[-1] < best_loss:\n",
    "        best_loss = yi[-1]\n",
    "        best = (tuple(Xi[-1]), bayes_result[tuple(Xi[-1])])\n",
    "        print(best, best_loss)\n",
    "        iters_since_improvement = 0\n",
    "    else:\n",
    "        iters_since_improvement += 1\n",
    "    iters += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "195e26ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 10\n"
     ]
    }
   ],
   "source": [
    "print(iters, iters_since_improvement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d55d91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.4144314690562643, 1.4144750171604252, 1.414431950844678, 1.4146699896205046, 1.4144195519707425, 1.414431223654621, 1.4144701537634776, 1.4144608438034143, 1.4146699896205046, 1.414440352616458, 1.4144313633518546, 1.4145594331844353, 1.4144226499638646, 1.414502349619847, 1.4145011836892192, 1.4144311585187468, 1.4145288947799417, 1.4146699896205046, 1.4144451531336388, 1.4144250921408401, 1.4144357210530596, 1.4145512483953038, 1.4146699896205046, 1.4145434548546838, 1.4144954755184773, 1.4144311384459856, 1.41449249307322, 1.4145545482127182, 1.4145105663959547, 1.4145644057011943, 1.4144321435300502, 1.414515618646807, 1.4145338438707298, 1.4145119443830194, 1.4145754485520399, 1.4144684165543642, 1.4144312174652836, 1.4144785295770945, 1.414431937302634, 1.41443123766918, 1.4145925643005763, 1.4146699896205046, 1.4144314851325108, 1.4144311166259054, 1.414441313310905, 1.414554496974795, 1.4144311694618894, 1.4144474667419493, 1.4146176857883916, 1.414418936660207, 1.4144243613924288, 1.4146699896205046, 1.41447319031867, 1.4146699896205046, 1.4144890167656556, 1.4144366491593985, 1.4144604709806508, 1.4144317201255165, 1.4145691417753148, 1.4146699896205046]\n"
     ]
    }
   ],
   "source": [
    "print(yi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d36a2a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0002510529602979261\n",
      "         cg_niter: 178\n",
      "     cg_stop_cond: 4\n",
      "           constr: []\n",
      "      constr_nfev: []\n",
      "      constr_nhev: []\n",
      "      constr_njev: []\n",
      "   constr_penalty: 1.0\n",
      " constr_violation: 0\n",
      "   execution_time: 1.0835003852844238\n",
      "              fun: 1.4140303826321499\n",
      "             grad: array([-4.67840073e-05, -3.29137596e-05, -7.00177878e-06, -8.03946151e-05,\n",
      "       -1.02562833e-04, -5.92857657e-06,  1.21595170e-04,  6.26374150e-05,\n",
      "       -1.12943171e-05,  3.95513064e-05,  8.59430520e-05, -1.41808961e-05,\n",
      "       -2.49413476e-04, -2.37622610e-04,  1.75049122e-04,  1.78455144e-04,\n",
      "        2.38380942e-05,  6.22859190e-05,  2.93887296e-06,  1.42446421e-05,\n",
      "        7.75149296e-05,  3.88841193e-05,  1.40122925e-05,  7.19264779e-05,\n",
      "        3.43156329e-05,  2.96321357e-05, -2.20093079e-05, -7.94260777e-05])\n",
      "              jac: []\n",
      "  lagrangian_grad: array([-4.67840073e-05, -3.29137596e-05, -7.00177878e-06, -8.03946151e-05,\n",
      "       -1.02562833e-04, -5.92857657e-06,  1.21595170e-04,  6.26374150e-05,\n",
      "       -1.12943171e-05,  3.95513064e-05,  8.59430520e-05, -1.41808961e-05,\n",
      "       -2.49413476e-04, -2.37622610e-04,  1.75049122e-04,  1.78455144e-04,\n",
      "        2.38380942e-05,  6.22859190e-05,  2.93887296e-06,  1.42446421e-05,\n",
      "        7.75149296e-05,  3.88841193e-05,  1.40122925e-05,  7.19264779e-05,\n",
      "        3.43156329e-05,  2.96321357e-05, -2.20093079e-05, -7.94260777e-05])\n",
      "          message: 'The maximum number of function evaluations is exceeded.'\n",
      "           method: 'equality_constrained_sqp'\n",
      "             nfev: 46\n",
      "             nhev: 0\n",
      "              nit: 46\n",
      "            niter: 46\n",
      "             njev: 46\n",
      "       optimality: 0.0002494134758273236\n",
      "           status: 0\n",
      "          success: False\n",
      "        tr_radius: 1.0078531902118064\n",
      "                v: []\n",
      "                x: array([-0.0581461 ,  1.1085918 , -0.12619399, -0.11757163,  0.128275  ,\n",
      "        0.30192025,  0.05176073, -0.13988686,  0.06948751,  0.03751725,\n",
      "        0.02978546, -0.01349286, -0.13190465,  0.00250421,  0.18706462,\n",
      "       -0.41014269, -0.05984026,  0.00235433,  0.17202039, -0.01564156,\n",
      "        0.00887062,  0.11573496, -0.02840494, -0.0686047 ,  0.04306836,\n",
      "       -0.06269881,  0.04709681,  0.19721624])\n"
     ]
    }
   ],
   "source": [
    "params = np.array([0, 1]+[0]*26).T\n",
    "print(objective(params, X, y)[0]-best_loss)\n",
    "result = minimize(objective_regularized, params, args=(X,y, 5.396718822844268e-05, 5.008739999507359e-07, 1e-10, 1e-10), method='trust-constr', jac=True, options={'maxiter':46})\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ccbf55db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0581461   1.1085918  -0.12619399 -0.11757163  0.128275    0.30192025\n",
      "  0.05176073 -0.13988686  0.06948751  0.03751725  0.02978546 -0.01349286\n",
      " -0.13190465  0.00250421] [ 0.18706462 -0.41014269 -0.05984026  0.00235433  0.17202039 -0.01564156\n",
      "  0.00887062  0.11573496 -0.02840494 -0.0686047   0.04306836 -0.06269881\n",
      "  0.04709681  0.19721624]\n",
      "[1.06646007 0.98612724 1.14846826 ... 1.76232645 1.82998954 1.10818671] [-0.01262578 -0.03233223 -0.03919247 ... -0.02632062 -0.04241146\n",
      " -0.014383  ]\n",
      "[ 1.         -1.29141164  0.45068298  0.49862778  0.40661941  0.37174072\n",
      "  0.32678337  0.2670287   0.35656678 -0.19429482 -0.2503565   0.2650725\n",
      " -0.22687692 -0.19009439]\n",
      "0.24040447221865505\n",
      "[0.]\n"
     ]
    }
   ],
   "source": [
    "best_params = result.x\n",
    "beta1 = best_params[:14]\n",
    "beta2 = best_params[14:]\n",
    "print(beta1, beta2)\n",
    "lambdas = np.exp(X@beta1)\n",
    "alphas = np.tanh(X@beta2)*.1-.024\n",
    "print(lambdas, alphas)\n",
    "print(X[np.argmax(alphas)])\n",
    "print(lambdas[np.argmax(alphas)])\n",
    "print(y[np.argmax(alphas)])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e782de22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((2.125243357620127e-06, 4.0994588896114135e-06, 2.237433025163467e-08, 3.228076038923881e-08), ('cg', 42)) 1.4144186334557831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bryant Ndongmo\\AppData\\Roaming\\Python\\Python39\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "C:\\Users\\Bryant Ndongmo\\AppData\\Roaming\\Python\\Python39\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((4.966463516121441e-06, 3.2002355458929274e-07, 5.101425463561947e-07, 4.4040564811717414e-08), ('trust-constr', 39)) 1.4144137887514072\n",
      "((2.129659009089934e-05, 3.606379053118981e-09, 2.669318106640796e-10, 3.278608492851997e-07), ('trust-constr', 47)) 1.414407831826694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bryant Ndongmo\\AppData\\Roaming\\Python\\Python39\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "C:\\Users\\Bryant Ndongmo\\AppData\\Roaming\\Python\\Python39\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "C:\\Users\\Bryant Ndongmo\\AppData\\Roaming\\Python\\Python39\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11724\\803594292.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# keep going, increase patience, messed up the inequality, fixed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[0miters\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m60\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miters_since_improvement\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m.8\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0miters\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbayes_objective\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Run a single iteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mXi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0myi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\skopt\\optimizer\\optimizer.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, func, n_iter)\u001b[0m\n\u001b[0;32m    644\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 646\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    647\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m         result = create_result(self.Xi, self.yi, self.space, self.rng,\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11724\\4096155067.py\u001b[0m in \u001b[0;36mbayes_objective\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mbayes_objective\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0ml1_wt_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml2_wt_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml1_wt_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml2_wt_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_validate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml1_wt_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml2_wt_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml1_wt_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml2_wt_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11724\\1425970670.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(X, y, l1_wt_1, l2_wt_1, l1_wt_2, l2_wt_2, splits, methods, min_iter, max_iter, patience, timeout, best_loss)\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m26\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjective_regularized\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ml1_wt_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml2_wt_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml1_wt_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml2_wt_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'maxiter'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    690\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_minimize_powell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbounds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    691\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'cg'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 692\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_minimize_cg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    693\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'bfgs'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    694\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_minimize_bfgs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_optimize.py\u001b[0m in \u001b[0;36m_minimize_cg\u001b[1;34m(fun, x0, args, jac, callback, gtol, norm, eps, maxiter, disp, return_all, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m   1650\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1651\u001b[0m             \u001b[0malpha_k\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mold_fval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mold_old_fval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgfkp1\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1652\u001b[1;33m                      _line_search_wolfe12(f, myfprime, xk, pk, gfk, old_fval,\n\u001b[0m\u001b[0;32m   1653\u001b[0m                                           \u001b[0mold_old_fval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mamin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mamax\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1654\u001b[0m                                           extra_condition=descent_condition)\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_optimize.py\u001b[0m in \u001b[0;36m_line_search_wolfe12\u001b[1;34m(f, fprime, xk, pk, gfk, old_fval, old_old_fval, **kwargs)\u001b[0m\n\u001b[0;32m   1085\u001b[0m     \u001b[0mextra_condition\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'extra_condition'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1086\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1087\u001b[1;33m     ret = line_search_wolfe1(f, fprime, xk, pk, gfk,\n\u001b[0m\u001b[0;32m   1088\u001b[0m                              \u001b[0mold_fval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mold_old_fval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1089\u001b[0m                              **kwargs)\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py\u001b[0m in \u001b[0;36mline_search_wolfe1\u001b[1;34m(f, fprime, xk, pk, gfk, old_fval, old_old_fval, args, c1, c2, amax, amin, xtol)\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[0mderphi0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgfk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m     stp, fval, old_fval = scalar_search_wolfe1(\n\u001b[0m\u001b[0;32m     85\u001b[0m             \u001b[0mphi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mderphi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mold_fval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mold_old_fval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mderphi0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m             c1=c1, c2=c2, amax=amax, amin=amin, xtol=xtol)\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py\u001b[0m in \u001b[0;36mscalar_search_wolfe1\u001b[1;34m(phi, derphi, phi0, old_phi0, derphi0, c1, c2, amax, amin, xtol)\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtask\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34mb'FG'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m             \u001b[0malpha1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m             \u001b[0mphi1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mphi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m             \u001b[0mderphi1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mderphi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py\u001b[0m in \u001b[0;36mphi\u001b[1;34m(s)\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mphi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[0mfc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxk\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mpk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mderphi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mfun\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    265\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_x_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 267\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    268\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_fun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    249\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_update_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_updated\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 251\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    252\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_updated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mupdate_fun\u001b[1;34m()\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    135\u001b[0m             \u001b[1;31m# Overwriting results in undefined behaviour because\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m             \u001b[1;31m# fun(self.x) will change self.x, with the two no longer linked.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m             \u001b[0mfx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m             \u001b[1;31m# Make sure the function returns a true scalar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misscalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[1;34m\"\"\" returns the the function value \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_if_needed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_optimize.py\u001b[0m in \u001b[0;36m_compute_if_needed\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[0mfg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11724\\3645292462.py\u001b[0m in \u001b[0;36mobjective_regularized\u001b[1;34m(params, X, y, l1_wt1, l2_wt1, l1_wt2, l2_wt2)\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mdloss_dbeta1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdloss_dp\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdp_dlamb\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdlamb_dbeta1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mdloss_dbeta2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdloss_dp\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdp_dalpha\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdalpha_dbeta2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mjac1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdloss_dbeta1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0ml1_wt1\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0ml2_wt1\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0mjac2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdloss_dbeta2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0ml1_wt2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0ml2_wt2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mjac\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjac1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjac2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# keep going, increase patience, messed up the inequality, fixed\n",
    "while iters < 60 or iters_since_improvement <= .8 * iters:\n",
    "    optimizer.run(bayes_objective, n_iter=1)  # Run a single iteration\n",
    "    Xi = optimizer.Xi\n",
    "    yi = optimizer.yi\n",
    "    if yi[-1] < best_loss:\n",
    "        best_loss = yi[-1]\n",
    "        best = (tuple(Xi[-1]), bayes_result[tuple(Xi[-1])])\n",
    "        print(best, best_loss)\n",
    "        iters_since_improvement = 0\n",
    "    else:\n",
    "        iters_since_improvement += 1\n",
    "    iters += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1e5c6d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "415 168\n",
      "0.000262157793810891\n",
      "         cg_niter: 164\n",
      "     cg_stop_cond: 4\n",
      "           constr: []\n",
      "      constr_nfev: []\n",
      "      constr_nhev: []\n",
      "      constr_njev: []\n",
      "   constr_penalty: 1.0\n",
      " constr_violation: 0\n",
      "   execution_time: 1.243955373764038\n",
      "              fun: 1.413990891651976\n",
      "             grad: array([-1.41723382e-04, -2.83695710e-04,  2.35550083e-05,  3.20191018e-05,\n",
      "       -3.85653630e-05, -4.31661904e-05,  1.58580175e-06,  1.81290459e-05,\n",
      "       -2.26991995e-05,  2.86218851e-05,  6.30041646e-05, -3.04244397e-06,\n",
      "       -9.25501738e-05, -1.09449511e-04,  6.39501560e-05,  7.59594636e-05,\n",
      "        5.63698790e-05,  6.59251034e-05, -2.18425300e-05,  4.84128680e-05,\n",
      "        6.84446543e-05, -9.49553321e-07,  4.12513479e-05,  8.62588716e-05,\n",
      "        2.66892165e-05,  5.39396417e-05,  1.31027317e-06, -7.46614323e-05])\n",
      "              jac: []\n",
      "  lagrangian_grad: array([-1.41723382e-04, -2.83695710e-04,  2.35550083e-05,  3.20191018e-05,\n",
      "       -3.85653630e-05, -4.31661904e-05,  1.58580175e-06,  1.81290459e-05,\n",
      "       -2.26991995e-05,  2.86218851e-05,  6.30041646e-05, -3.04244397e-06,\n",
      "       -9.25501738e-05, -1.09449511e-04,  6.39501560e-05,  7.59594636e-05,\n",
      "        5.63698790e-05,  6.59251034e-05, -2.18425300e-05,  4.84128680e-05,\n",
      "        6.84446543e-05, -9.49553321e-07,  4.12513479e-05,  8.62588716e-05,\n",
      "        2.66892165e-05,  5.39396417e-05,  1.31027317e-06, -7.46614323e-05])\n",
      "          message: 'The maximum number of function evaluations is exceeded.'\n",
      "           method: 'equality_constrained_sqp'\n",
      "             nfev: 47\n",
      "             nhev: 0\n",
      "              nit: 47\n",
      "            niter: 47\n",
      "             njev: 47\n",
      "       optimality: 0.00028369570977988806\n",
      "           status: 0\n",
      "          success: False\n",
      "        tr_radius: 1.0\n",
      "                v: []\n",
      "                x: array([-0.05364149,  1.10380284, -0.12802523, -0.11350656,  0.14479146,\n",
      "        0.28412562,  0.05881972, -0.16418116,  0.09105764,  0.03975226,\n",
      "        0.01133762, -0.04496442, -0.13345358,  0.01891682,  0.15382581,\n",
      "       -0.39355931, -0.0270141 ,  0.02267041,  0.14426045,  0.00933024,\n",
      "        0.02893208,  0.09975885, -0.00599008, -0.03602106,  0.04387653,\n",
      "       -0.03198676,  0.05784553,  0.16704192])\n"
     ]
    }
   ],
   "source": [
    "#check intermediate solution\n",
    "print(iters, iters_since_improvement)\n",
    "params = np.array([0, 1]+[0]*26).T\n",
    "print(objective(params, X, y)[0]-best_loss)\n",
    "result = minimize(objective_regularized, params, args=(X,y,2.129659009089934e-05, 3.606379053118981e-09, 2.669318106640796e-10, 3.278608492851997e-07), method='trust-constr', jac=True, options={'maxiter':47})\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c6b488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((1.8538560054940012e-06, 5.230241397255493e-05, 8.194542657522409e-07, 4.510245535853731e-06), ('cg', 40)) 1.4143978159067125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bryant Ndongmo\\AppData\\Roaming\\Python\\Python39\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "C:\\Users\\Bryant Ndongmo\\AppData\\Roaming\\Python\\Python39\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "C:\\Users\\Bryant Ndongmo\\AppData\\Roaming\\Python\\Python39\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "C:\\Users\\Bryant Ndongmo\\AppData\\Roaming\\Python\\Python39\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    }
   ],
   "source": [
    "# think patience .5 is good\n",
    "while iters < 60 or iters_since_improvement <= .5 * iters:\n",
    "    optimizer.run(bayes_objective, n_iter=1)  # Run a single iteration\n",
    "    Xi = optimizer.Xi\n",
    "    yi = optimizer.yi\n",
    "    if yi[-1] < best_loss:\n",
    "        best_loss = yi[-1]\n",
    "        best = (tuple(Xi[-1]), bayes_result[tuple(Xi[-1])])\n",
    "        print(best, best_loss)\n",
    "        iters_since_improvement = 0\n",
    "    else:\n",
    "        iters_since_improvement += 1\n",
    "    iters += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "027b900c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     fun: 1.4140171673547357\n",
      "     jac: array([ 1.60818655e-03,  9.11761236e-04,  1.68561855e-04,  1.62857393e-04,\n",
      "       -1.02858986e-04, -2.37427906e-05,  9.01219239e-05,  7.15965542e-05,\n",
      "        4.96687570e-05, -1.86547106e-04, -3.02006011e-04,  1.25986205e-04,\n",
      "       -1.16683193e-04, -3.31531921e-04,  8.12020736e-05,  2.00403732e-04,\n",
      "        6.96726538e-05,  5.03742600e-05, -6.44933615e-05,  5.24889351e-05,\n",
      "        5.36279625e-05, -3.34018961e-05,  4.84577172e-05,  6.02152525e-05,\n",
      "       -2.06689912e-05,  6.28381656e-05, -1.14768483e-05, -1.11378601e-04])\n",
      " message: 'Maximum number of iterations has been exceeded.'\n",
      "    nfev: 75\n",
      "     nit: 40\n",
      "    njev: 75\n",
      "  status: 1\n",
      " success: False\n",
      "       x: array([-4.62319386e-02,  1.09529993e+00, -8.10055683e-02, -6.15535437e-02,\n",
      "        9.38547919e-02,  2.04022371e-01,  3.82601271e-02, -1.38517403e-01,\n",
      "        5.79986228e-02,  2.44191826e-02,  4.11575600e-03, -4.76232303e-02,\n",
      "       -9.72798389e-02,  4.99641666e-03,  9.32562650e-02, -3.10782439e-01,\n",
      "        8.71577801e-03,  4.02503902e-02,  9.65152783e-02,  3.33392781e-02,\n",
      "        4.55263935e-02,  6.88530381e-02,  1.51259265e-02,  2.34688581e-03,\n",
      "        4.01700326e-02, -6.41320951e-04,  5.73317380e-02,  1.12787744e-01])\n"
     ]
    }
   ],
   "source": [
    "#Final solution\n",
    "params = np.array([0, 1]+[0]*26).T\n",
    "result = minimize(objective_regularized, params, args=(X,y,1.8538560054940012e-06, 5.230241397255493e-05, 8.194542657522409e-07, 4.510245535853731e-06), method='cg', jac=True, options={'maxiter':40})\n",
    "param_names = ['intercept', 'loglines']\n",
    "param_names += ['xgoals_lines_for', 'goals_lines_for', \n",
    "            'goals_xgoals_for','wxgoals_lines_for', \n",
    "            'wgoals_lines_for', 'wgoals_xgoals_for']\n",
    "param_names += ['xgoals_lines_ag', 'goals_lines_ag', \n",
    "                'goals_xgoals_ag','wxgoals_lines_ag', \n",
    "                'wgoals_lines_ag', 'wgoals_xgoals_ag']\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e741c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients for lambda\n",
      "            Parameter      Coef\n",
      "0           intercept -0.046232\n",
      "1            loglines  1.095300\n",
      "2    xgoals_lines_for -0.081006\n",
      "3     goals_lines_for -0.061554\n",
      "4    goals_xgoals_for  0.093855\n",
      "5   wxgoals_lines_for  0.204022\n",
      "6    wgoals_lines_for  0.038260\n",
      "7   wgoals_xgoals_for -0.138517\n",
      "8     xgoals_lines_ag  0.057999\n",
      "9      goals_lines_ag  0.024419\n",
      "10    goals_xgoals_ag  0.004116\n",
      "11   wxgoals_lines_ag -0.047623\n",
      "12    wgoals_lines_ag -0.097280\n",
      "13   wgoals_xgoals_ag  0.004996\n",
      "\n",
      "Coefficients for alpha\n",
      "            Parameter      Coef\n",
      "0           intercept  0.093256\n",
      "1            loglines -0.310782\n",
      "2    xgoals_lines_for  0.008716\n",
      "3     goals_lines_for  0.040250\n",
      "4    goals_xgoals_for  0.096515\n",
      "5   wxgoals_lines_for  0.033339\n",
      "6    wgoals_lines_for  0.045526\n",
      "7   wgoals_xgoals_for  0.068853\n",
      "8     xgoals_lines_ag  0.015126\n",
      "9      goals_lines_ag  0.002347\n",
      "10    goals_xgoals_ag  0.040170\n",
      "11   wxgoals_lines_ag -0.000641\n",
      "12    wgoals_lines_ag  0.057332\n",
      "13   wgoals_xgoals_ag  0.112788\n",
      "\n",
      "Sorted coefficients for lambda\n",
      "            Parameter      Coef\n",
      "1            loglines  1.095300\n",
      "5   wxgoals_lines_for  0.204022\n",
      "7   wgoals_xgoals_for -0.138517\n",
      "12    wgoals_lines_ag -0.097280\n",
      "4    goals_xgoals_for  0.093855\n",
      "2    xgoals_lines_for -0.081006\n",
      "3     goals_lines_for -0.061554\n",
      "8     xgoals_lines_ag  0.057999\n",
      "11   wxgoals_lines_ag -0.047623\n",
      "0           intercept -0.046232\n",
      "6    wgoals_lines_for  0.038260\n",
      "9      goals_lines_ag  0.024419\n",
      "13   wgoals_xgoals_ag  0.004996\n",
      "10    goals_xgoals_ag  0.004116\n",
      "\n",
      "Sorted coefficients for alpha\n",
      "            Parameter      Coef\n",
      "1            loglines -0.310782\n",
      "13   wgoals_xgoals_ag  0.112788\n",
      "4    goals_xgoals_for  0.096515\n",
      "0           intercept  0.093256\n",
      "7   wgoals_xgoals_for  0.068853\n",
      "12    wgoals_lines_ag  0.057332\n",
      "6    wgoals_lines_for  0.045526\n",
      "3     goals_lines_for  0.040250\n",
      "10    goals_xgoals_ag  0.040170\n",
      "5   wxgoals_lines_for  0.033339\n",
      "8     xgoals_lines_ag  0.015126\n",
      "2    xgoals_lines_for  0.008716\n",
      "9      goals_lines_ag  0.002347\n",
      "11   wxgoals_lines_ag -0.000641\n"
     ]
    }
   ],
   "source": [
    "best_params = result.x\n",
    "beta1 = np.array(best_params[:14])\n",
    "beta2 = np.array(best_params[14:])\n",
    "\n",
    "print('Coefficients for lambda')\n",
    "lambda_coefs = pd.DataFrame()\n",
    "lambda_coefs['Parameter'] = param_names\n",
    "lambda_coefs['Coef'] = beta1\n",
    "print(lambda_coefs)\n",
    "\n",
    "print()\n",
    "\n",
    "print('Coefficients for alpha')\n",
    "alpha_coefs = pd.DataFrame()\n",
    "alpha_coefs['Parameter'] = param_names\n",
    "alpha_coefs['Coef'] = beta2\n",
    "print(alpha_coefs)\n",
    "\n",
    "print()\n",
    "\n",
    "print('Sorted coefficients for lambda')\n",
    "print(lambda_coefs.iloc[lambda_coefs['Coef'].abs().argsort()[::-1]])\n",
    "\n",
    "print()\n",
    "\n",
    "print('Sorted coefficients for alpha')\n",
    "print(alpha_coefs.iloc[alpha_coefs['Coef'].abs().argsort()[::-1]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c49d108",
   "metadata": {},
   "source": [
    "Get Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f609cafa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Null Lambda</th>\n",
       "      <th>Model Lambda</th>\n",
       "      <th>Null Alpha</th>\n",
       "      <th>Model Alpha</th>\n",
       "      <th>Null Prediction</th>\n",
       "      <th>Model Prediction</th>\n",
       "      <th>Goals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.079527</td>\n",
       "      <td>1.076298</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>-0.020297</td>\n",
       "      <td>1.054226</td>\n",
       "      <td>1.054888</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.949978</td>\n",
       "      <td>0.985569</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>-0.030603</td>\n",
       "      <td>0.927713</td>\n",
       "      <td>0.956304</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.094548</td>\n",
       "      <td>1.142372</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>-0.034942</td>\n",
       "      <td>1.068895</td>\n",
       "      <td>1.103803</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.373471</td>\n",
       "      <td>1.371363</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>-0.025032</td>\n",
       "      <td>1.341280</td>\n",
       "      <td>1.337874</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.681730</td>\n",
       "      <td>0.679763</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>-0.031761</td>\n",
       "      <td>0.665752</td>\n",
       "      <td>0.658837</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36475</th>\n",
       "      <td>1.904947</td>\n",
       "      <td>1.941786</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>-0.032600</td>\n",
       "      <td>1.860299</td>\n",
       "      <td>1.880482</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36476</th>\n",
       "      <td>1.897266</td>\n",
       "      <td>1.844239</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>-0.022457</td>\n",
       "      <td>1.852799</td>\n",
       "      <td>1.803732</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36477</th>\n",
       "      <td>1.707834</td>\n",
       "      <td>1.759997</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>-0.026602</td>\n",
       "      <td>1.667807</td>\n",
       "      <td>1.714391</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36478</th>\n",
       "      <td>1.760862</td>\n",
       "      <td>1.833753</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>-0.039223</td>\n",
       "      <td>1.719591</td>\n",
       "      <td>1.764542</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36479</th>\n",
       "      <td>1.136870</td>\n",
       "      <td>1.114355</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>-0.018169</td>\n",
       "      <td>1.110225</td>\n",
       "      <td>1.094469</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36480 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Null Lambda  Model Lambda  Null Alpha  Model Alpha  Null Prediction  \\\n",
       "0         1.079527      1.076298      -0.024    -0.020297         1.054226   \n",
       "1         0.949978      0.985569      -0.024    -0.030603         0.927713   \n",
       "2         1.094548      1.142372      -0.024    -0.034942         1.068895   \n",
       "3         1.373471      1.371363      -0.024    -0.025032         1.341280   \n",
       "4         0.681730      0.679763      -0.024    -0.031761         0.665752   \n",
       "...            ...           ...         ...          ...              ...   \n",
       "36475     1.904947      1.941786      -0.024    -0.032600         1.860299   \n",
       "36476     1.897266      1.844239      -0.024    -0.022457         1.852799   \n",
       "36477     1.707834      1.759997      -0.024    -0.026602         1.667807   \n",
       "36478     1.760862      1.833753      -0.024    -0.039223         1.719591   \n",
       "36479     1.136870      1.114355      -0.024    -0.018169         1.110225   \n",
       "\n",
       "       Model Prediction  Goals  \n",
       "0              1.054888    2.0  \n",
       "1              0.956304    0.0  \n",
       "2              1.103803    0.0  \n",
       "3              1.337874    1.0  \n",
       "4              0.658837    1.0  \n",
       "...                 ...    ...  \n",
       "36475          1.880482    2.0  \n",
       "36476          1.803732    2.0  \n",
       "36477          1.714391    0.0  \n",
       "36478          1.764542    1.0  \n",
       "36479          1.094469    0.0  \n",
       "\n",
       "[36480 rows x 7 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lamb = np.exp(X@beta1)\n",
    "model_alpha = np.tanh(X@beta2)*.1-.024\n",
    "model_preds = model_lamb/(1-model_alpha)\n",
    "\n",
    "null_params = np.array([0, 1]+[0]*26).T\n",
    "null_beta1 = null_params[:14]\n",
    "null_beta2 = null_params[14:]\n",
    "null_lamb = np.exp(X@null_beta1)\n",
    "null_alpha = np.tanh(X@null_beta2)*.1-.024\n",
    "null_preds = null_lamb/(1-null_alpha)\n",
    "\n",
    "predictions = pd.DataFrame()\n",
    "predictions['Null Lambda'] = null_lamb\n",
    "predictions['Model Lambda'] = model_lamb\n",
    "predictions['Null Alpha'] = null_alpha\n",
    "predictions['Model Alpha'] = model_alpha\n",
    "predictions['Null Prediction'] = null_preds\n",
    "predictions['Model Prediction'] = model_preds\n",
    "predictions['Goals'] = data['goals']\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275fbf7b",
   "metadata": {},
   "source": [
    "Let's analyze the significance of the model's cross validation performance. We will create a set of rv_discrete variables and define loss distributions based on the null model and compare with alternative performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "02eddd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import rv_discrete\n",
    "# Function to create distributions and losses\n",
    "def create_dists(null_lamb, pred_lamb, pred_alpha):\n",
    "    dists = []  # List to store probability distributions\n",
    "    diffs = []  # List to store diffs\n",
    "\n",
    "    # Iterate over lines and preds\n",
    "    for nl, pl, pa in zip(null_lamb, pred_lamb, pred_alpha):\n",
    "        probs = []  # List to store individual probabilities\n",
    "        diff = []  # List to store individual losses\n",
    "        i = 0\n",
    "        cum = 0.0\n",
    "        model_cum = 0.0\n",
    "        \n",
    "        # Calculate probabilities and losses until cumulative probability exceeds 0.9999\n",
    "        while cum < 0.9999:\n",
    "            pmf = gpmf(i, nl, -.024)[0]  # Calculate the probability mass function\n",
    "            pmf_item = pmf.item()  # Extract the value of the probability mass function\n",
    "            cum += pmf_item  # Update the cumulative probability\n",
    "            probs.append(pmf_item)  # Append the probability to the list of probabilities\n",
    "            null_loss = -np.log(pmf_item)\n",
    "            \n",
    "            model_pmf = gpmf(i, pl, pa)[0].item()\n",
    "            model_cum += model_pmf\n",
    "            model_loss = -np.log(model_pmf)\n",
    "            \n",
    "            diff.append(model_loss-null_loss)  # Append the performance difference to the list of diffs\n",
    "            i += 1\n",
    "\n",
    "        dists.append(probs + [1.0 - cum])  # Append the probabilities with the remaining probability to the dists list\n",
    "        diffs.append(diff + [np.log(1.0 - cum)-np.log(1.0 - model_cum)])  # Append the diffs with the final diff to the diffs list\n",
    "\n",
    "    return dists, diffs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0a0ffc5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[0.33975622072276246,\n",
       "   0.3756850905659686,\n",
       "   0.19847124624491194,\n",
       "   0.06668561478012162,\n",
       "   0.01600444692442506,\n",
       "   0.002921215740291131,\n",
       "   0.0004215879971412979,\n",
       "   5.4577024377944205e-05],\n",
       "  [0.3867495555666178,\n",
       "   0.3763278944983847,\n",
       "   0.17384227544982522,\n",
       "   0.050725752934923214,\n",
       "   0.010494562201952384,\n",
       "   0.0016381121432676447,\n",
       "   0.0002004310603750101,\n",
       "   2.141614465400732e-05],\n",
       "  [0.33469074448294284,\n",
       "   0.37523359184493643,\n",
       "   0.2011194483587246,\n",
       "   0.06860634422941982,\n",
       "   0.01672888259271146,\n",
       "   0.003104747250082757,\n",
       "   0.0004559902481301966,\n",
       "   6.025099305184689e-05],\n",
       "  [0.2532265660634139,\n",
       "   0.3562474167396221,\n",
       "   0.24183264104175253,\n",
       "   0.10551528616049612,\n",
       "   0.03325542489976834,\n",
       "   0.008067137466267178,\n",
       "   0.001567203649191174,\n",
       "   0.0002504952459394491,\n",
       "   3.782873354929439e-05],\n",
       "  [0.5057415175193619,\n",
       "   0.35315374017239287,\n",
       "   0.11462011964722214,\n",
       "   0.022957955892396232,\n",
       "   0.00317770246716092,\n",
       "   0.00032254030698794734,\n",
       "   2.642399447794208e-05]],\n",
       " [[-0.0032285900352493346,\n",
       "   0.003470028099936018,\n",
       "   0.003131107240706532,\n",
       "   -0.0047077192685964775,\n",
       "   -0.020550338761841758,\n",
       "   -0.044946940206895825,\n",
       "   -0.07849947328592588,\n",
       "   -0.12771857026477207],\n",
       "  [0.0355911551633018,\n",
       "   -0.007791991931925368,\n",
       "   -0.03891026244013873,\n",
       "   -0.056631369008871335,\n",
       "   -0.05967858054790298,\n",
       "   -0.04660681847384218,\n",
       "   -0.01577381924534116,\n",
       "   0.04072090956809227],\n",
       "  [0.04782322809336459,\n",
       "   -0.005882994674699882,\n",
       "   -0.04130866639255926,\n",
       "   -0.056888522556883814,\n",
       "   -0.050871271152532316,\n",
       "   -0.02129077928634615,\n",
       "   0.03406833213600624,\n",
       "   0.1293616516028564],\n",
       "  [-0.0021073023804467628,\n",
       "   -0.001603912384089634,\n",
       "   0.000516124986557065,\n",
       "   0.004344355030662772,\n",
       "   0.009979369188492626,\n",
       "   0.017527496391307906,\n",
       "   0.027103577457345374,\n",
       "   0.038831834412333066,\n",
       "   0.05490098356581363],\n",
       "  [-0.0019669476869375035,\n",
       "   -0.006838340654562236,\n",
       "   0.01338500821666555,\n",
       "   0.062225191096149324,\n",
       "   0.14390225932881773,\n",
       "   0.26351797102613084,\n",
       "   0.43938343808996905]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dists, diffs = create_dists(predictions['Null Lambda'], predictions['Model Lambda'], predictions['Model Alpha'])\n",
    "dists[:5], diffs[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9824cb2f",
   "metadata": {},
   "source": [
    "Now create a random variable for each game determining the possible log losses incurred under the null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f8eca257",
   "metadata": {},
   "outputs": [],
   "source": [
    "rvs = []  # List to store random variables\n",
    "for diff, dist in zip(diffs, dists):\n",
    "    rv = rv_discrete(values=(diff, dist))  # Create a random variable with the loss values and distribution\n",
    "    rvs.append(rv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd72c75",
   "metadata": {},
   "source": [
    "Start with a normal approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ac0b6128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18.74605134420189, 6.140716261454438)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_mean = 0\n",
    "total_var = 0\n",
    "for rv in rvs:\n",
    "    total_mean += rv.mean()\n",
    "    total_var += rv.var()\n",
    "total_std = np.sqrt(total_var)\n",
    "total_mean, total_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a62ec28",
   "metadata": {},
   "source": [
    "Determine p-value of alternative model outperforming null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ee0f960c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-Value=0.00113378625480783\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "z = -total_mean / total_std\n",
    "\n",
    "print(f'P-Value={norm.cdf(z)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd71aea",
   "metadata": {},
   "source": [
    "Bootstrap samples (slow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3d206f1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[21.76720648497192,\n",
       " 28.611362651739483,\n",
       " 14.215455455621308,\n",
       " 18.658853654946068,\n",
       " 21.263124026418435,\n",
       " 28.351899492381982,\n",
       " 14.067468652718807,\n",
       " 20.491185067618865,\n",
       " 14.042923665585029,\n",
       " 22.440327183131433]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_diffs = []\n",
    "for _ in range(500):\n",
    "    diff = 0\n",
    "    for rv in rvs:\n",
    "        diff += rv.rvs()\n",
    "    sample_diffs.append(diff)\n",
    "sample_diffs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "41cfdb23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 12.,  35.,  47.,  70., 101., 107.,  59.,  45.,  17.,   7.]),\n",
       " array([ 2.76497913,  6.02251254,  9.28004595, 12.53757936, 15.79511276,\n",
       "        19.05264617, 22.31017958, 25.56771299, 28.8252464 , 32.0827798 ,\n",
       "        35.34031321]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(sample_diffs)\n",
    "#Seems to fit normal distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5680d77",
   "metadata": {},
   "source": [
    "Export games with lines so shelve doesn't need to be used, also export transformed training data for reuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2d6e2425",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('all seasons with lines.csv', index=False)\n",
    "data.to_csv('transformed_training_data.csv', index=False)\n",
    "predictions.to_csv('predictions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c8f2b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
