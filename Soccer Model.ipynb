{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d539ef6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shelve\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import *\n",
    "from patsy import dmatrices\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import rv_discrete\n",
    "from skopt import Optimizer, space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc80ae90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7633\n",
      "7821\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Div</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>H_Line</th>\n",
       "      <th>A_Line</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>HXG</th>\n",
       "      <th>...</th>\n",
       "      <th>AvgC&lt;2.5</th>\n",
       "      <th>AHCh</th>\n",
       "      <th>B365CAHH</th>\n",
       "      <th>B365CAHA</th>\n",
       "      <th>PCAHH</th>\n",
       "      <th>PCAHA</th>\n",
       "      <th>MaxCAHH</th>\n",
       "      <th>MaxCAHA</th>\n",
       "      <th>AvgCAHH</th>\n",
       "      <th>AvgCAHA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SC0</td>\n",
       "      <td>08/01/20</td>\n",
       "      <td>12:30</td>\n",
       "      <td>Aberdeen</td>\n",
       "      <td>Rangers</td>\n",
       "      <td>0.724756</td>\n",
       "      <td>1.770761</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.67</td>\n",
       "      <td>...</td>\n",
       "      <td>1.78</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.83</td>\n",
       "      <td>2.02</td>\n",
       "      <td>1.90</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.94</td>\n",
       "      <td>2.12</td>\n",
       "      <td>1.85</td>\n",
       "      <td>1.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SC0</td>\n",
       "      <td>08/01/20</td>\n",
       "      <td>15:00</td>\n",
       "      <td>Dundee United</td>\n",
       "      <td>St Johnstone</td>\n",
       "      <td>1.094679</td>\n",
       "      <td>1.066453</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.49</td>\n",
       "      <td>...</td>\n",
       "      <td>1.52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.93</td>\n",
       "      <td>1.93</td>\n",
       "      <td>1.91</td>\n",
       "      <td>1.99</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.99</td>\n",
       "      <td>1.92</td>\n",
       "      <td>1.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SC0</td>\n",
       "      <td>08/01/20</td>\n",
       "      <td>15:00</td>\n",
       "      <td>Hibernian</td>\n",
       "      <td>Kilmarnock</td>\n",
       "      <td>1.511150</td>\n",
       "      <td>0.977880</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.24</td>\n",
       "      <td>...</td>\n",
       "      <td>1.76</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1.96</td>\n",
       "      <td>1.94</td>\n",
       "      <td>2.02</td>\n",
       "      <td>1.94</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SC0</td>\n",
       "      <td>08/01/20</td>\n",
       "      <td>15:00</td>\n",
       "      <td>St Mirren</td>\n",
       "      <td>Livingston</td>\n",
       "      <td>0.945194</td>\n",
       "      <td>1.182613</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>1.53</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.85</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.88</td>\n",
       "      <td>2.01</td>\n",
       "      <td>1.90</td>\n",
       "      <td>2.08</td>\n",
       "      <td>1.83</td>\n",
       "      <td>2.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SC0</td>\n",
       "      <td>08/02/20</td>\n",
       "      <td>16:30</td>\n",
       "      <td>Celtic</td>\n",
       "      <td>Hamilton</td>\n",
       "      <td>3.534317</td>\n",
       "      <td>0.420098</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3.07</td>\n",
       "      <td>...</td>\n",
       "      <td>3.79</td>\n",
       "      <td>-3.00</td>\n",
       "      <td>1.98</td>\n",
       "      <td>1.88</td>\n",
       "      <td>2.01</td>\n",
       "      <td>1.88</td>\n",
       "      <td>2.04</td>\n",
       "      <td>1.92</td>\n",
       "      <td>1.96</td>\n",
       "      <td>1.87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 109 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Div      Date   Time       HomeTeam      AwayTeam    H_Line    A_Line  \\\n",
       "0  SC0  08/01/20  12:30       Aberdeen       Rangers  0.724756  1.770761   \n",
       "1  SC0  08/01/20  15:00  Dundee United  St Johnstone  1.094679  1.066453   \n",
       "2  SC0  08/01/20  15:00      Hibernian    Kilmarnock  1.511150  0.977880   \n",
       "3  SC0  08/01/20  15:00      St Mirren    Livingston  0.945194  1.182613   \n",
       "4  SC0  08/02/20  16:30         Celtic      Hamilton  3.534317  0.420098   \n",
       "\n",
       "   FTHG  FTAG   HXG  ...  AvgC<2.5  AHCh  B365CAHH  B365CAHA PCAHH  PCAHA  \\\n",
       "0     0     1  0.67  ...      1.78  1.00      1.83      2.02  1.90   2.00   \n",
       "1     1     1  1.49  ...      1.52  0.00      1.93      1.93  1.91   1.99   \n",
       "2     2     1  1.24  ...      1.76 -0.50      1.95      1.90  1.96   1.94   \n",
       "3     1     0  0.94  ...      1.53  0.25      1.85      2.00  1.88   2.01   \n",
       "4     5     1  3.07  ...      3.79 -3.00      1.98      1.88  2.01   1.88   \n",
       "\n",
       "   MaxCAHH  MaxCAHA  AvgCAHH  AvgCAHA  \n",
       "0     1.94     2.12     1.85     1.99  \n",
       "1     2.00     1.99     1.92     1.93  \n",
       "2     2.02     1.94     1.95     1.88  \n",
       "3     1.90     2.08     1.83     2.01  \n",
       "4     2.04     1.92     1.96     1.87  \n",
       "\n",
       "[5 rows x 109 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialize dataframe, lines calculated with function to be explained later, xgs extracted from footystats sheets\n",
    "season2021 =pd.read_csv(\"combinefd21.csv\")\n",
    "season2022 =pd.read_csv(\"combinefd22.csv\")\n",
    "season2023 =pd.read_csv(\"combinefd23.csv\")\n",
    "df = pd.concat([season2021, season2022, season2023]).reset_index(drop=True)\n",
    "print(len(season2021))\n",
    "print(len(season2022))\n",
    "with shelve.open('inputs') as i:\n",
    "    hls = i['hls']\n",
    "    als = i['als']\n",
    "df.insert(5, 'A_Line', als)\n",
    "df.insert(5, 'H_Line', hls)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac76f385",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_data(decay): # decay factor used to compute weighted averages for recency\n",
    "    # dictionaries to store stats for each team\n",
    "    goals_for = {}\n",
    "    goals_ag = {}\n",
    "    xgoals_for = {}\n",
    "    xgoals_ag = {}\n",
    "    lines_for = {}\n",
    "    lines_ag = {}\n",
    "\n",
    "    # parameter names for the metrics\n",
    "    param_names = ['goals', 'loglines']\n",
    "    param_names += ['xgoals_lines_for', 'goals_xgoals_for', \n",
    "                    'goals_lines_for','wxgoals_lines_for', \n",
    "                    'wgoals_xgoals_for', 'wgoals_lines_for']\n",
    "    param_names += ['xgoals_lines_ag', 'goals_xgoals_ag', \n",
    "                    'goals_lines_ag','wxgoals_lines_ag', \n",
    "                    'wgoals_xgoals_ag', 'wgoals_lines_ag']\n",
    "\n",
    "    # minimum sample size for teams before betting on a match\n",
    "    min_sample_size = 8\n",
    "\n",
    "    # list to store training data rows\n",
    "    training_rows = []\n",
    "\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for index, row in df.iterrows(): \n",
    "        if index == 7633 or index == 7633+7821:\n",
    "            goals_for = {}\n",
    "            goals_ag = {}\n",
    "            xgoals_for = {}\n",
    "            xgoals_ag = {}\n",
    "            lines_for = {}\n",
    "            lines_ag = {}\n",
    "            \n",
    "        home_team = row['HomeTeam']\n",
    "        away_team = row['AwayTeam']\n",
    "        h_line = row['H_Line']\n",
    "        a_line = row['A_Line']\n",
    "        h_goals = row['FTHG']\n",
    "        a_goals = row['FTAG']\n",
    "\n",
    "        # Check if both teams have sufficient data for betting\n",
    "        if home_team in goals_for and away_team in goals_for and len(goals_for[home_team]) >= min_sample_size and len(goals_for[away_team]) >= min_sample_size:\n",
    "\n",
    "            # Calculate various metrics for home and away teams\n",
    "            h_xgoals_vs_lines_for, h_goals_vs_lines_for, h_goals_vs_xgoals_for, h_xgoals_vs_lines_ag, h_goals_vs_lines_ag, h_goals_vs_xgoals_ag = metrics(home_team, goals_for, goals_ag, xgoals_for, xgoals_ag, lines_for, lines_ag)\n",
    "            a_xgoals_vs_lines_for, a_goals_vs_lines_for, a_goals_vs_xgoals_for, a_xgoals_vs_lines_ag, a_goals_vs_lines_ag, a_goals_vs_xgoals_ag = metrics(away_team, goals_for, goals_ag, xgoals_for, xgoals_ag, lines_for, lines_ag)\n",
    "            weighted_h_xgoals_vs_lines_for, weighted_h_goals_vs_lines_for, weighted_h_goals_vs_xgoals_for, weighted_h_xgoals_vs_lines_ag, weighted_h_goals_vs_lines_ag, weighted_h_goals_vs_xgoals_ag = metrics(home_team, goals_for, goals_ag, xgoals_for, xgoals_ag, lines_for, lines_ag, True, decay)\n",
    "            weighted_a_xgoals_vs_lines_for, weighted_a_goals_vs_lines_for, weighted_a_goals_vs_xgoals_for, weighted_a_xgoals_vs_lines_ag, weighted_a_goals_vs_lines_ag, weighted_a_goals_vs_xgoals_ag = metrics(away_team, goals_for, goals_ag, xgoals_for, xgoals_ag, lines_for, lines_ag, True, decay)\n",
    "\n",
    "            # Apply the convert_metric function to each metric for home and away teams\n",
    "            home_metrics = [h_xgoals_vs_lines_for, h_goals_vs_lines_for, h_goals_vs_xgoals_for, weighted_h_xgoals_vs_lines_for, weighted_h_goals_vs_lines_for, weighted_h_goals_vs_xgoals_for]\n",
    "            home_metrics += [a_xgoals_vs_lines_ag, a_goals_vs_lines_ag, a_goals_vs_xgoals_ag, weighted_a_xgoals_vs_lines_ag, weighted_a_goals_vs_lines_ag, weighted_a_goals_vs_xgoals_ag]\n",
    "            away_metrics = [a_xgoals_vs_lines_for, a_goals_vs_lines_for, a_goals_vs_xgoals_for, weighted_a_xgoals_vs_lines_for, weighted_a_goals_vs_lines_for, weighted_a_goals_vs_xgoals_for]\n",
    "            away_metrics += [h_xgoals_vs_lines_ag, h_goals_vs_lines_ag, h_goals_vs_xgoals_ag, weighted_h_xgoals_vs_lines_ag, weighted_h_goals_vs_lines_ag, weighted_h_goals_vs_xgoals_ag]\n",
    "\n",
    "            for i in range(12):\n",
    "                home_metrics[i] = convert_metric(h_line, home_metrics[i])\n",
    "                away_metrics[i] = convert_metric(a_line, away_metrics[i])\n",
    "\n",
    "            # Create complete metrics Series for home and away teams\n",
    "            complete_home_metrics = pd.Series([h_goals, np.log(h_line)]+home_metrics,index=param_names)\n",
    "            complete_away_metrics = pd.Series([a_goals, np.log(a_line)]+away_metrics,index=param_names)\n",
    "\n",
    "            # Append the metrics Series to the training_rows list\n",
    "            training_rows.append(complete_home_metrics)\n",
    "            training_rows.append(complete_away_metrics)\n",
    "\n",
    "        # Update the dictionaries with new data for goals, expected goals, and lines\n",
    "        h_xg = row['HXG']\n",
    "        a_xg = row['AXG']\n",
    "        goals_for[home_team] = goals_for.setdefault(home_team, [])+[h_goals]\n",
    "        goals_for[away_team] = goals_for.setdefault(away_team, [])+[a_goals]\n",
    "        goals_ag[home_team] = goals_ag.setdefault(home_team, [])+[a_goals]\n",
    "        goals_ag[away_team] = goals_ag.setdefault(away_team, [])+[h_goals]\n",
    "        xgoals_for[home_team] = xgoals_for.setdefault(home_team, [])+[h_xg]\n",
    "        xgoals_for[away_team] = xgoals_for.setdefault(away_team, [])+[a_xg]\n",
    "        xgoals_ag[home_team] = xgoals_ag.setdefault(home_team, [])+[a_xg]\n",
    "        xgoals_ag[away_team] = xgoals_ag.setdefault(away_team, [])+[h_xg]\n",
    "        lines_for[home_team] = lines_for.setdefault(home_team, [])+[h_line]\n",
    "        lines_for[away_team] = lines_for.setdefault(away_team, [])+[a_line]\n",
    "        lines_ag[home_team] = lines_ag.setdefault(home_team, [])+[a_line]\n",
    "        lines_ag[away_team] = lines_ag.setdefault(away_team, [])+[h_line]\n",
    "    return training_rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "402b7f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty lists to store test decays and losses\n",
    "test_decays = []\n",
    "losses = []\n",
    "\n",
    "# Define the compute_loss function with decay as the input\n",
    "def compute_loss(decay):\n",
    "    # Gather training data based on the decay value\n",
    "    training_rows = gather_data(decay)\n",
    "    \n",
    "    # Concatenate the training data horizontally and transpose it\n",
    "    data = pd.concat(training_rows, axis=1).T\n",
    "    \n",
    "    # Define the initial expression with the dependent variable 'goals' and the independent variable 'loglines'\n",
    "    expr = 'goals ~ loglines'\n",
    "    \n",
    "    # Append the remaining column names to the expression\n",
    "    for name in data.columns[2:]:\n",
    "        expr += ' + ' + name\n",
    "    \n",
    "    # Create design matrices (y_train, X_train) using the formula expr and the data\n",
    "    y_train, X_train = dmatrices(expr, data, return_type='dataframe')\n",
    "    \n",
    "    # Fit the model on the training data\n",
    "    result = fit(X_train, y_train)\n",
    "    \n",
    "    # Calculate the parameters, considering values below a certain threshold as 0\n",
    "    params = np.where(np.abs(result.x) <= 1e-5, 0, result.x)\n",
    "    \n",
    "    # Compute the loss based on the optimized parameters\n",
    "    loss = result.fun\n",
    "    \n",
    "    # Print the decay and loss values\n",
    "    print(decay, loss)\n",
    "    \n",
    "    # Append the decay and loss to the respective lists\n",
    "    test_decays.append(decay)\n",
    "    losses.append(loss)\n",
    "    \n",
    "    # Return the computed loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff773291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 1.4147040538759068\n",
      "0.6 1.4146993097229448\n",
      "0.7 1.4146891196291453\n",
      "0.8 1.4146695977335835\n",
      "0.9 1.414649507472981\n",
      "0.85 1.4146584504957167\n",
      "0.86 1.41465637427215\n",
      "0.87 1.4146544263076066\n",
      "0.88 1.4146526121663345\n",
      "0.89 1.4146509635623503\n",
      "0.9 1.414649507472981\n",
      "0.91 1.4146482962434348\n",
      "0.92 1.414647338386015\n",
      "0.93 1.414646707655017\n",
      "0.94 1.4146464304251236\n",
      "0.95 1.4146465890314712\n",
      "0.95 1.4146465890314712\n",
      "0.96 1.4147106613811347\n",
      "0.97 1.4147096375885022\n",
      "0.98 1.4147085104928534\n",
      "0.99 1.4147086094711447\n"
     ]
    }
   ],
   "source": [
    "# Initialize the best_loss variable with infinity\n",
    "best_loss = float('inf')\n",
    "\n",
    "# Iterate over a range of values from 5 to 9 (inclusive)\n",
    "for i in range(5, 10):\n",
    "    # Compute the loss for the current decay value\n",
    "    loss = compute_loss(i / 10)\n",
    "    \n",
    "    # Update the best_loss and best_decay variables if the current loss is smaller\n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        best_decay = i / 10\n",
    "\n",
    "# Compute a seed value based on the best_decay\n",
    "seed = int(best_decay * 100)\n",
    "\n",
    "# Iterate over a range of values from seed-5 to seed+5\n",
    "for i in range(seed - 5, seed + 6):\n",
    "    # Compute the loss for the current decay value\n",
    "    loss = compute_loss(i / 100)\n",
    "    \n",
    "    # Update the best_loss and best_decay variables if the current loss is smaller\n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        best_decay = i / 100\n",
    "\n",
    "# Iterate over a range of values from 95 to 99\n",
    "for i in range(95, 100):\n",
    "    # Compute the loss for the current decay value\n",
    "    loss = compute_loss(i / 100)\n",
    "    \n",
    "    # Update the best_loss and best_decay variables if the current loss is smaller\n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        best_decay = i / 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc605410",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Scatter plot of decay values vs. losses\n",
    "plt.scatter(test_decays, losses)\n",
    "plt.xlabel('Decay Factor')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "\n",
    "# Gather the training data based on the best decay value\n",
    "training_rows = gather_data(best_decay)\n",
    "data = pd.concat(training_rows, axis=1).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1a4e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bryant Ndongmo\\AppData\\Roaming\\Python\\Python39\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "C:\\Users\\Bryant Ndongmo\\AppData\\Roaming\\Python\\Python39\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "C:\\Users\\Bryant Ndongmo\\AppData\\Roaming\\Python\\Python39\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "C:\\Users\\Bryant Ndongmo\\AppData\\Roaming\\Python\\Python39\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    }
   ],
   "source": [
    "expr = 'goals ~ loglines'\n",
    "for name in data.columns[2:]:\n",
    "    expr += ' + '+name\n",
    "\n",
    "l1_wts = []\n",
    "l2_wts = []\n",
    "cv_losses = []\n",
    "\n",
    "def cross_validate(l1_wt, l2_wt):\n",
    "    # Split the data into training and test sets\n",
    "    df_train = data[:round(len(data)*.8)]\n",
    "    df_test = data[round(len(data)*.8):]\n",
    "    \n",
    "    # Create design matrices for training and test data\n",
    "    y_train, X_train = dmatrices(expr, df_train, return_type='dataframe')\n",
    "    y_test, X_test = dmatrices(expr, df_test, return_type='dataframe')\n",
    "    \n",
    "    # Fit regularized model on the training data\n",
    "    result = fit_regularized(X_train, y_train, l1_wt, l2_wt)\n",
    "    params = np.where(np.abs(result.x) <= 1e-5, 0, result.x)\n",
    "    null = [0,1]+[0]*(len(params)-2)\n",
    "    \n",
    "    # Calculate the loss difference between the model and null model on the test data\n",
    "    loss = objective_function(params, X_test, y_test) - objective_function(null, X_test, y_test)\n",
    "    \n",
    "    # Store the l1_wt, l2_wt, and loss values for analysis\n",
    "    l1_wts.append(l1_wt)\n",
    "    l2_wts.append(l2_wt)\n",
    "    cv_losses.append(loss)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def objective(x):\n",
    "    l1_wt, l2_wt = x\n",
    "    return cross_validate(l1_wt, l2_wt)\n",
    "\n",
    "sp = [space.Real(1e-10, .001, name='l1_wt', prior='log-uniform'), space.Real(1e-10, .1, name='l2_wt', prior='log-uniform')]\n",
    "# Create an instance of Optimizer for Bayesian optimization and optimize\n",
    "optimizer = Optimizer(sp, base_estimator='gp')\n",
    "# Perform Bayesian optimization iterations\n",
    "_ = optimizer.run(objective, 500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd498b25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a scatter plot\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.scatter(l1_wts, l2_wts, c=cv_losses, cmap='viridis')\n",
    "\n",
    "# Add color bar legend\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_label('CV-Loss')\n",
    "\n",
    "# Set labels for x and y axes\n",
    "plt.xlabel('l1_wt')\n",
    "plt.ylabel('l2_wt')\n",
    "\n",
    "# Set a title for the plot\n",
    "plt.title('Experimental Responses')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "# Find optimal point\n",
    "A=np.linspace(0.001, 1, 1000)\n",
    "B=np.linspace(0.001, 1, 1000)\n",
    "points = []\n",
    "for a in A:\n",
    "    for b in B:\n",
    "        points.append(np.array([a, b]))\n",
    "surrogate_model = optimizer.models[-1]\n",
    "scores = np.array([surrogate_model.predict(point.reshape(1,-1)) for point in points])\n",
    "f_l1_wts = []\n",
    "f_l2_wts = []\n",
    "f_cv_losses = []\n",
    "for point, score in zip(points, scores):\n",
    "    conv = point.copy()\n",
    "    i = -10\n",
    "    j1 = -3\n",
    "    j2 = -1\n",
    "    conv[0] = 10**(conv[0]*(j1-i)+i)\n",
    "    conv[1] = 10**(conv[1]*(j2-i)+i)\n",
    "    f_l1_wts.append(conv[0])\n",
    "    f_l2_wts.append(conv[1])\n",
    "    f_cv_losses.append(score)\n",
    "    \n",
    "# Create a scatter plot\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.scatter(f_l1_wts, f_l2_wts, c=f_cv_losses, cmap='viridis')\n",
    "\n",
    "# Add color bar legend\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_label('CV-Loss')\n",
    "\n",
    "# Set labels for x and y axes\n",
    "plt.xlabel('l1_wt')\n",
    "plt.ylabel('l2_wt')\n",
    "\n",
    "# Set a title for the plot\n",
    "plt.title('Fitted Responses')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()  \n",
    "\n",
    "#find the best predicted point\n",
    "argmin = np.argmin(scores)\n",
    "point = points[argmin]\n",
    "conv = point.copy()\n",
    "i = -10\n",
    "j1 = -3\n",
    "j2 = -1\n",
    "conv[0] = 10**(conv[0]*(j1-i)+i)\n",
    "conv[1] = 10**(conv[1]*(j2-i)+i)\n",
    "print(point, conv, scores[argmin])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520535f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train model with tuned parameters on all data\n",
    "y, X = dmatrices(expr, data, return_type='dataframe')\n",
    "best_l1_wt, best_l2_wt =conv\n",
    "result = fit_regularized(X, y, best_l1_wt,best_l2_wt)\n",
    "params = np.where(np.abs(result.x) <= 1e-5, 0, result.x) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d95313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph performance of the model to evaluate smoothness\n",
    "beta = params\n",
    "null = [0,1]+[0]*(X.shape[1]-2)\n",
    "alpha = -0.024\n",
    "y_flat = y.values.flatten()\n",
    "mu_errors = np.log(gpmf(y_flat, alpha, np.exp(X @ beta)))\n",
    "null_errors = np.log(gpmf(y_flat, alpha, np.exp(X @ null)))\n",
    "game = list(range(len(mu_errors))) \n",
    "plt.scatter(game, np.cumsum(mu_errors-null_errors))\n",
    "plt.xlabel('Game')\n",
    "plt.ylabel('Performance')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c8455e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Idea 2: given the null, compute the distribution of losses between the null and alternative and return the z-score assuming\n",
    "# that sum of all the difference is approximately normal\n",
    "# Extract the 'loglines' values from the X DataFrame starting from 80% of the length\n",
    "lines = np.exp(X['loglines'][round(len(X)*.8):])\n",
    "\n",
    "# Function to create distributions and losses\n",
    "def create_dists(lines):\n",
    "    dists = []  # List to store probability distributions\n",
    "    losses = []  # List to store losses\n",
    "\n",
    "    # Iterate over lines and preds\n",
    "    for line, pred in zip(lines, preds):\n",
    "        probs = []  # List to store individual probabilities\n",
    "        l = []  # List to store individual losses\n",
    "        i = 0\n",
    "        cum = 0.0\n",
    "        \n",
    "        # Calculate probabilities and losses until cumulative probability exceeds 0.9999\n",
    "        while cum < 0.9999:\n",
    "            pmf = gpmf(i, -0.024, line)  # Calculate the probability mass function\n",
    "            pmf_item = pmf.item()  # Extract the value of the probability mass function\n",
    "            cum += pmf_item  # Update the cumulative probability\n",
    "            probs.append(pmf_item)  # Append the probability to the list of probabilities\n",
    "            l.append(-np.log(pmf_item))  # Append the loss to the list of losses\n",
    "            i += 1\n",
    "\n",
    "        dists.append(probs + [1.0 - cum])  # Append the probabilities with the remaining probability to the dists list\n",
    "        losses.append(l + [-np.log(1.0 - cum)])  # Append the losses with the final loss to the losses list\n",
    "\n",
    "    return dists, losses\n",
    "\n",
    "# Call the create_dists function to compute dists and losses\n",
    "dists, losses = create_dists(lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bbfee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "expr = 'goals ~ loglines'\n",
    "# Iterate over the columns of the data DataFrame starting from the third column\n",
    "for name in data.columns[2:]:\n",
    "    expr += ' + '+name  # Append column names to the expression for linear regression\n",
    "\n",
    "l1_wts = []  # List to store l1_wt values\n",
    "l2_wts = []  # List to store l2_wt values\n",
    "cv_scores = []  # List to store cross-validation scores\n",
    "\n",
    "# Function for cross-validation\n",
    "def cross_validate(l1_wt, l2_wt):   \n",
    "    # Split the data into training and test sets\n",
    "    df_train = data[:round(len(data)*.8)]\n",
    "    df_test =  data[round(len(data)*.8):]  \n",
    "    y_train, X_train = dmatrices(expr, df_train, return_type='dataframe')\n",
    "    y_test, X_test = dmatrices(expr, df_test, return_type='dataframe')\n",
    "    \n",
    "    # Fit a regularized linear regression model\n",
    "    result = fit_regularized(X_train, y_train, l1_wt, l2_wt)\n",
    "    params = np.where(np.abs(result.x) <= 1e-5, 0, result.x)  # Threshold parameters close to zero\n",
    "    null = [0,1]+[0]*(len(params)-2)  # Null model parameters\n",
    "\n",
    "    preds = np.exp(X_test @ params)  # Generate predictions using the fitted model\n",
    "\n",
    "    rvs = []  # List to store random variables\n",
    "    for pred, loss, dist in zip(preds, losses, dists):\n",
    "        loss_diff = []\n",
    "        # Calculate the difference between predicted and actual losses for each observation\n",
    "        for i in range(len(loss)):\n",
    "            pred_pmf = gpmf(i, -.024, pred)\n",
    "            loss_diff.append(-np.log(pred_pmf)-loss[i])\n",
    "        rv = rv_discrete(values=(loss_diff, dist))  # Create a random variable with the loss differences and distribution\n",
    "        rvs.append(rv)\n",
    "\n",
    "    mean = var = 0\n",
    "    for rv in rvs:\n",
    "        mean += rv.mean()  # Compute the mean of the random variables\n",
    "        var += rv.var()  # Compute the variance of the random variables\n",
    "    \n",
    "    std = np.sqrt(var)  # Calculate the standard deviation\n",
    "    model_loss = objective_function(params, X_test, y_test)  # Calculate the loss of the model predictions\n",
    "    null_loss = objective_function([0,1]+[0]*(len(params)-2), X_test, y_test)  # Calculate the loss of the null model\n",
    "    x = (model_loss-null_loss)*len(X_test)  # Compute the difference in losses scaled by the number of observations\n",
    "    l1_wts.append(l1_wt)\n",
    "    l2_wts.append(l2_wt)\n",
    "    score = (x-mean)/std  # Compute the cross-validation score\n",
    "    cv_scores.append(score)\n",
    "    \n",
    "    return score\n",
    "\n",
    "def objective(x):\n",
    "    l1_wt, l2_wt = x\n",
    "    return cross_validate(l1_wt, l2_wt)\n",
    "\n",
    "sp = [space.Real(1e-10, .001, name='l1_wt', prior='log-uniform'), space.Real(1e-10, .1, name='l2_wt', prior='log-uniform')]\n",
    "# Create an instance of Optimizer for Bayesian optimization and optimize\n",
    "optimizer = Optimizer(sp, base_estimator='gp')\n",
    "# Perform Bayesian optimization iterations\n",
    "_ = optimizer.run(objective, 500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36834fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.scatter(l1_wts, l2_wts, c=cv_scores, cmap='viridis')\n",
    "\n",
    "# Add color bar legend\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_label('CV-Score')\n",
    "\n",
    "# Set labels for x and y axes\n",
    "plt.xlabel('l1_wt')\n",
    "plt.ylabel('l2_wt')\n",
    "\n",
    "# Set a title for the plot\n",
    "plt.title('Experimental Responses')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "# Find optimal point\n",
    "A=np.linspace(0.001, 1, 1000)\n",
    "B=np.linspace(0.001, 1, 1000)\n",
    "points = []\n",
    "for a in A:\n",
    "    for b in B:\n",
    "        points.append(np.array([a, b]))\n",
    "surrogate_model = optimizer.models[-1]\n",
    "scores = np.array([surrogate_model.predict(point.reshape(1,-1)) for point in points])\n",
    "f_l1_wts = []\n",
    "f_l2_wts = []\n",
    "f_cv_losses = []\n",
    "for point, score in zip(points, scores):\n",
    "    conv = point.copy()\n",
    "    i = -10\n",
    "    j1 = -3\n",
    "    j2 = -1\n",
    "    conv[0] = 10**(conv[0]*(j1-i)+i)\n",
    "    conv[1] = 10**(conv[1]*(j2-i)+i)\n",
    "    f_l1_wts.append(conv[0])\n",
    "    f_l2_wts.append(conv[1])\n",
    "    f_cv_losses.append(score)\n",
    "    \n",
    "# Create a scatter plot\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.scatter(f_l1_wts, f_l2_wts, c=f_cv_losses, cmap='viridis')\n",
    "\n",
    "# Add color bar legend\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_label('CV-Loss')\n",
    "\n",
    "# Set labels for x and y axes\n",
    "plt.xlabel('l1_wt')\n",
    "plt.ylabel('l2_wt')\n",
    "\n",
    "# Set a title for the plot\n",
    "plt.title('Fitted Responses')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()  \n",
    "\n",
    "argmin = np.argmin(scores)\n",
    "point = points[argmin]\n",
    "conv = point.copy()\n",
    "i = -10\n",
    "j1 = -3\n",
    "j2 = -1\n",
    "conv[0] = 10**(conv[0]*(j1-i)+i)\n",
    "conv[1] = 10**(conv[1]*(j2-i)+i)\n",
    "print(point, conv, scores[argmin])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609c3b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train model with tuned parameters on all data\n",
    "y, X = dmatrices(expr, data, return_type='dataframe')\n",
    "best_l1_wt, best_l2_wt =conv\n",
    "result = fit_regularized(X, y, best_l1_wt,best_l2_wt)\n",
    "params = np.where(np.abs(result.x) <= 1e-5, 0, result.x) \n",
    "print(params)\n",
    "\n",
    "#graph performance\n",
    "beta = params\n",
    "null = [0,1]+[0]*(X.shape[1]-2)\n",
    "alpha = -0.024\n",
    "y_flat = y.values.flatten()\n",
    "mu_errors = np.log(gpmf(y_flat, alpha, np.exp(X @ beta)))\n",
    "null_errors = np.log(gpmf(y_flat, alpha, np.exp(X @ null)))\n",
    "game = list(range(len(mu_errors))) \n",
    "plt.scatter(game, np.cumsum(mu_errors-null_errors))\n",
    "plt.xlabel('Game')\n",
    "plt.ylabel('Performance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17de87e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
